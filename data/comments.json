{"comments":[{"Id":"150264","PostId":"299744","CreationDate":"2008-11-20T18:21:56.600","UserId":"31655","Body":"very useful! thanks"},{"Id":"150280","PostId":"299744","CreationDate":"2008-11-20T18:28:15.357","UserId":"35296","Body":"No problem, fun mental workout!"},{"Id":"150955","PostId":"299744","CreationDate":"2008-11-20T23:30:50.987","UserId":"12030","Body":"It's not clear to me how having 'tickets' that you attempt to claim in sequence is a significant improvement over simply retrying the read\/modify\/write to update the master entity. Certainly it doesn't seem worth the extra overhead, especially if you have large amounts of stock."},{"Id":"160324","PostId":"299744","CreationDate":"2008-11-25T23:26:29.683","UserId":"35296","Body":"From my perspective, the ticket convention is &quot;simpler&quot; to build.  Failed updates on the master entry require you to reload the document, perform your operation again, and then save.  The ticket thing allows you to try and &quot;claim&quot; something without having to request more data."},{"Id":"160327","PostId":"299744","CreationDate":"2008-11-25T23:27:44.750","UserId":"35296","Body":"Also, it depends what sort of overhead you're worried about.  You're either going to fight with increased contention, or have additional storage requirements.  Given that a ticket can also double as a purchase record, I don't know that there'd be as much of a storage problem as you think."},{"Id":"162204","PostId":"316875","CreationDate":"2008-11-26T19:38:36.773","UserId":"35296","Body":"Yes, this would make sense!"},{"Id":"422438","PostId":"568675","CreationDate":"2009-03-04T10:50:20.690","UserId":"39392","Body":"That wouldn't really help in the situation being discussed, i.e. contention on single docs from multiple users."},{"Id":"458181","PostId":"337344","CreationDate":"2009-03-13T22:21:35.433","UserId":"44330","Body":"&quot;I am asking pears to an elm&quot;: interesting idiom... http:\/\/www.cababstractsplus.org\/abstracts\/Abstract.aspx?AcNo=20043154615"},{"Id":"481406","PostId":"667141","CreationDate":"2009-03-20T20:36:05.980","UserId":"27978","Body":"When you schema varies a lot you will have a hard time with relational databases. This is where XML databases or key-value pair databases work best. or you could use IBM DB2 and have both relational data and XML data managed by a single database engine. Get it free - check http:\/\/FreeDB2.com."},{"Id":"482094","PostId":"667673","CreationDate":"2009-03-21T01:05:54.243","UserId":"67441","Body":"+1 for specifics.  What about the scenario where part of your data is hierarchical e.g. a sales\/stock database where there are customers, products, orders, etc, tens of thousands of products with tens of thousands of product categories which are hierarchical? "},{"Id":"482099","PostId":"667141","CreationDate":"2009-03-21T01:08:53.003","UserId":"67441","Body":"+1 for interesting. I like questions like this where people discuss when things must be done differently e.g. &quot;When is xml not actually a sensible method for data storage?&quot;, etc, etc, etc"},{"Id":"482103","PostId":"667878","CreationDate":"2009-03-21T01:11:30.360","UserId":"67441","Body":"Do you have any real world examples of when you may be in this situation to help less experienced developers (meaning me) get a feel for when this kind of issue may crop up?"},{"Id":"482111","PostId":"667355","CreationDate":"2009-03-21T01:17:41.560","UserId":"67441","Body":"+1 for the specifics of relational database paradigm assumptions.  I think most beginner-to-intermediate devs (like me) forget that it was designed with assumptions and just don't remember it may not be the best way. In what types of systems would you come across the need for more flexibility?"},{"Id":"482153","PostId":"667355","CreationDate":"2009-03-21T01:49:40.940","UserId":"20860","Body":"@JM: It *is* the best way if you need the database to enforce a consistent set of attributes on all entities in a given relation.  You'd need more flexibility if you have a collection of entities with  variable attributes, e.g. a product catalog with many different types of products."},{"Id":"482220","PostId":"667673","CreationDate":"2009-03-21T02:47:27.197","UserId":"726","Body":"If the hierarchy is more wide than deep, then a relational DB could still be a reasonable choice. If the maximum depth is fixed, then you can always denormalize and flatten the hierarchy (not very pretty, though)."},{"Id":"482967","PostId":"668500","CreationDate":"2009-03-21T15:44:36.003","UserId":"726","Body":"I can sympathize, having taken over relational DBs from designers quite unfamiliar with relational theory. However, if the situation calls for an RDB, then the developer should learn relational theory--or hire someone proficient--rather than choose an alternate, and therefore lesser, technology."},{"Id":"511472","PostId":"568675","CreationDate":"2009-03-30T18:51:25.793","UserId":"2140","Body":"Starting with CouchDB 0.9, the semantics of bulk updates have changed."},{"Id":"639702","PostId":"667673","CreationDate":"2009-05-06T19:07:13.697","UserId":"2238","Body":"Wouldn't nested sets work pretty well even in relational databases? http:\/\/en.wikipedia.org\/wiki\/Nested_set_model"},{"Id":"639728","PostId":"667673","CreationDate":"2009-05-06T19:12:37.850","UserId":"31641","Body":"There's nothing conflicting about a hierarchy. That's exactly what JOINs with 1:m relationships are. And why shouldn't you use an RDBMS just because you emphasize reading over writing? That's 99% of web sites. Ditto for &quot;no ad hoc queries&quot;. This answer is just plain wrong. All three points are wrong. And it didn't even provide any suggested alternatives as requested. And it gets 10 votes plus accepted? Looks like a setup question to me. "},{"Id":"639760","PostId":"667673","CreationDate":"2009-05-06T19:18:34.480","UserId":"82660","Body":"Great answer dude !"},{"Id":"641253","PostId":"667673","CreationDate":"2009-05-07T03:02:44.787","UserId":"726","Body":"le dorfier: 1. Hierarchies are 1:m *reflexive* relationships, which are easy enough to JOIN with to find the next level, but not for joins to arbitrary depths. 2. True, most read-only websites use RDBMSs, but again, referential integrity and transactional consistency are not nearly as useful for read-only use. 3. Ad-hoc queries are the reason relational theory exists--review your E.F. Codd. 4. Sorry, not a setup. In fact, I am a great believer in the power of RDBMSs, and teach courses in using them, but one has to grasp the limitations in any technology."},{"Id":"860787","PostId":"823509","CreationDate":"2009-06-26T14:18:28.030","UserId":"379","Body":"this point has now been discussed in the SO podcast 59."},{"Id":"913118","PostId":"337861","CreationDate":"2009-07-08T14:53:43.163","UserId":"74727","Body":"I know you answered this a long time ago, but I thought I'd ask... When do you &quot;need&quot; to normalize?  Isn't normalization a choice\/best practice?"},{"Id":"937957","PostId":"823509","CreationDate":"2009-07-13T19:13:22.583","UserId":"53013","Body":"This is not an answer, but a question. If you want to know the answer, ask the question!"},{"Id":"983909","PostId":"1164587","CreationDate":"2009-07-22T11:32:29.970","UserId":"1423","Body":"This has nothing to do with the question, a blog post (or somewhere else) would be a more appropriate place for that."},{"Id":"984257","PostId":"1164587","CreationDate":"2009-07-22T12:45:12.550","UserId":"142745","Body":"Not entirely true. Albeit I did take the opportunity to get things right, mine was also a reply to Matthew, who I seconded when he said that (the original) NoSQL is not really meant for large-scale databases. But you are also partly right, so I'm going to post a second and more technical post."},{"Id":"984959","PostId":"1164587","CreationDate":"2009-07-22T14:30:57.073","UserId":"133535","Body":"You could have just posted this as a comment to his question if you wanted to thank him. Leave the Answer section for Answers."},{"Id":"985034","PostId":"1164587","CreationDate":"2009-07-22T14:42:13.717","UserId":"142745","Body":"BTW, if you keep downrating my post you may end-up with attracting more attention to it from readers :-) But I quit the debate here, I don't want to take more bandwidth with this. Sorry for having jumped-in."},{"Id":"1012505","PostId":"1189911","CreationDate":"2009-07-27T20:07:38.273","UserId":"116154","Body":"key\/value databases the old new thing.  "},{"Id":"1026269","PostId":"1203010","CreationDate":"2009-07-29T21:08:22.837","UserId":"119365","Body":"I am not sure what map\/reduce has to do with your question.  mapreduce is a framework for running many jobs in parallel on large data sets.  (http:\/\/en.wikipedia.org\/wiki\/MapReduce)"},{"Id":"1026274","PostId":"1203010","CreationDate":"2009-07-29T21:09:00.373","UserId":"119365","Body":"actually i think what you might be thinking of is schemaless datastores"},{"Id":"1026596","PostId":"1189911","CreationDate":"2009-07-29T22:10:48.773","UserId":"37539","Body":"For anyone uber-interested, there's a long-form discussion going on on the NoSQL google group, here: http:\/\/groups.google.com\/group\/nosql-discussion\/browse_thread\/thread\/bbe3aa69071fd7b9"},{"Id":"1026615","PostId":"1203010","CreationDate":"2009-07-29T22:14:21.090","UserId":"4812","Body":"Out of the corner of my eye, it looked as if someone was asking about &quot;shemale performance&quot;! Childish, I know..."},{"Id":"1026642","PostId":"1203010","CreationDate":"2009-07-29T22:19:09.110","UserId":"13663","Body":"I'm curious why you think Couch isn't appropriate for a read mostly scenario? What has been your experience that has brought this conclusion? Most complaints I have seen re: Couch aren't with it's read performance."},{"Id":"1030227","PostId":"1203010","CreationDate":"2009-07-30T14:26:14.913","UserId":"127660","Body":"I replaced a Ruby\/MySQL combo with couchdb. I haven't done any hard numbers performance tests but the overall 'feel' is definitely slower. Note that this is a couchapp and it's not just couchdb, mochiweb is also in the stack as well. "},{"Id":"1030247","PostId":"1203457","CreationDate":"2009-07-30T14:28:22.663","UserId":"127660","Body":"Great suggestion. I'll investigate varnish!"},{"Id":"1039984","PostId":"1215297","CreationDate":"2009-08-01T02:43:42.360","UserId":"37539","Body":"But what about cases where the account is debited but the tension doc isn't changed? Any failure scenario between those two points, if they are not atomic, will cause permanent inconsistency, right? Something about the process has to be atomic, that's the point of a transaction."},{"Id":"1043220","PostId":"667355","CreationDate":"2009-08-02T10:42:27.800","UserId":"36710","Body":"I really like this answer. I'm so tired of hearing &quot;a RDBMS can model anything&quot; in discussions, but that's not what really matters. It's about the assumptions of the relational database paradigm and if these make a good fit for the problem at hand or not."},{"Id":"1044222","PostId":"667355","CreationDate":"2009-08-02T18:14:34.673","UserId":"20860","Body":"@nawroth:  Yep!  You don't use a screwdriver to drive in a nail, and you don't use a hammer to drive in a screw.  Maybe it's *possible* to do either of those things, given enough determination and patience.  But it'd be easier, more efficient, and more successful if you use the right tools."},{"Id":"1044818","PostId":"1215297","CreationDate":"2009-08-02T22:08:39.790","UserId":"9069","Body":"Yes, you're correct, in this case -- while the tension is not resolved -- there will be inconsistency. However the inconsistency is only temporary until the next scan for tension documents detects this. That's the trade of in this case, a kind of eventual consistency regarding time. As long as you decrent the source acount first and later increment the target account this can be acceptable. \n\nBut beware: tension documents wont give you ACID transactions on top of REST. But they can be a good tradeoff between pure REST and ACID."},{"Id":"1071877","PostId":"1245379","CreationDate":"2009-08-07T15:27:08.667","UserId":"47680","Body":"Yeah, I'm pretty sure anyone mentioning NoSQL is talking about the concept and not a specific tool."},{"Id":"1071887","PostId":"1245362","CreationDate":"2009-08-07T15:28:24.423","UserId":"47680","Body":"Never knew that NoSQL was an actual product but everyone talking about NoSQL nowadays mean non-RDBMS (see Jon's answer, for example)."},{"Id":"1071962","PostId":"1245379","CreationDate":"2009-08-07T15:42:54.113","UserId":"25538","Body":"Yeah I don't think I realized there was a specific NoSQL tool before I read David's answer.  I always think of the concept.  Thanks, Artem."},{"Id":"1071993","PostId":"1245362","CreationDate":"2009-08-07T15:47:21.280","UserId":"25538","Body":"Looking at the article (great article), I think he's referring to the NoSQL movement rather than the specific tool."},{"Id":"1079507","PostId":"823509","CreationDate":"2009-08-09T23:48:55.990","UserId":"103017","Body":"A simple answer is double-entry bookkeeping &lt;http:\/\/en.wikipedia.org\/wiki\/Double-entry_bookkeeping&gt;.  A transfer from Alice's account to Bob's is represented by a debit document for $100 with Alice's account id, and a credit document with Bob's account id.  You sum the debit and credit documents referencing an account to compute account balance. If you use CouchDB's bulk update API &lt;http:\/\/wiki.apache.org\/couchdb\/HTTP_Bulk_Document_API&gt; you can create both the debit and credit documents in a single atomic operation. Or you can put both the debit and the credit in one document."},{"Id":"1079521","PostId":"1215297","CreationDate":"2009-08-09T23:57:02.743","UserId":"103017","Body":"Imagine every tension document has a timestamp, and account documents have a 'last-tension-applied' field - or a list of applied tensions. When you debit the source account you also update the 'last-tension-applied' field. Those two operations are atomic because they are on the same document. The target account also has a similar field. That way the system can always tell which tension docs have been applied to which accounts."},{"Id":"1178755","PostId":"1343565","CreationDate":"2009-08-27T20:29:15.107","UserId":"56066","Body":"or cache things into temp tables or even html files hourly or more often, if required."},{"Id":"1179766","PostId":"1343565","CreationDate":"2009-08-28T00:07:30.020","UserId":"18424","Body":"This has actually been running for about 1 year on MySQL.  30M rows is not very many, but scanning the activity table (which is carefully optimized and indexes) is one of the biggest consumers of database time.\n\nI could just move this to a slave server (especially because replication lag is a total non-issue for this data), which is what I will do if I don't come up with something that suits the data better."},{"Id":"1182825","PostId":"1343565","CreationDate":"2009-08-28T14:02:03.443","UserId":"13724","Body":"I suspect that the application design is letting it down; if you plan things properly and test it well, I can't see how 30M rows could create a problem - at least if you're running on decent hardware. getting decent hardware is much cheaper than a major code change, so do that first :)"},{"Id":"1182926","PostId":"1343565","CreationDate":"2009-08-28T14:17:00.710","UserId":"18424","Body":"I don't have any performance problems today. My biggest problem right now is inflexibility. Changing the schema on a 30M row table in MySQL is a royal pain. "},{"Id":"1187776","PostId":"1343565","CreationDate":"2009-08-29T14:48:23.877","UserId":"18424","Body":"Yeah - a key\/value store would not fit my needs."},{"Id":"1191328","PostId":"1342741","CreationDate":"2009-08-30T20:22:24.687","UserId":"18424","Body":"I noticed that Kellan Elliott-McCrea from Flickr has bookmarked the article about what FriendFeed does with MySQL (bret.appspot.com\/entry\/how-friendfeed-uses-mysql\/\u2026) with a note saying that it is &quot;very similar&quot; to what Flickr does for activity streams."},{"Id":"1231510","PostId":"1387872","CreationDate":"2009-09-07T20:52:16.100","UserId":"18424","Body":"I think that you might be right (MySQL may be the most performant open source option RDBMS or otherwise)... The tough part is that the more that I work with this, the more crazy stuff like this makes sense: http:\/\/bret.appspot.com\/entry\/how-friendfeed-uses-mysql"},{"Id":"1276439","PostId":"1164587","CreationDate":"2009-09-16T10:17:38.543","UserId":"96435","Body":"Carlo, you're a new SO user that hasn't read the FAQ, hence the downvotes. Answers section belongs to.. answers indeed, and others to comments. Once you have 50 reputation you will be able to leave comments. "},{"Id":"1367859","PostId":"1512978","CreationDate":"2009-10-03T12:53:13.917","UserId":"162742","Body":"Very informative, many thanks."},{"Id":"1377568","PostId":"1429406","CreationDate":"2009-10-05T22:17:29.230","UserId":"18424","Body":"CouchDB views do look like they'd work well for me as well. I haven't had a chance to do much testing because insert and view creation performance with millions of records is.. not so good."},{"Id":"1384517","PostId":"1528860","CreationDate":"2009-10-07T00:59:40.277","UserId":"185307","Body":"I did see that project, and I like where they're heading, but they seem more like a minimal wiki\/Google Sites kind of project based on the limited available documentation.  That's fine, but I'm hoping that a more heavyweight application in the vein of Drupal\/Joomla will enter this arena.  Bookmarked it though."},{"Id":"1385545","PostId":"1529134","CreationDate":"2009-10-07T06:52:36.290","UserId":"185307","Body":"I regret now differentiating between the brittleness of the database and the system as a whole, because having systems designed to be scalable from the start is really where my interests lie.  Cache management is a great strategy that will certainly help with load, but it will not by itself solve scaling issues for you.  And, as you yourself point out, there is almost always going to be some  amount of dynamic content for an interactive site.  What I hope for is a CMS that: scales cleanly to arbitrary numbers of instances, and whose database is not the part I worry about most."},{"Id":"1402057","PostId":"1544012","CreationDate":"2009-10-09T17:35:08.203","UserId":"142017","Body":"Sorry, I didn't mention before, but one of the requirements I'm looking for is persistence.  Looks like an interesting project nonetheless."},{"Id":"1402061","PostId":"1543965","CreationDate":"2009-10-09T17:35:54.693","UserId":"142017","Body":"Persistence is a must.  Sorry, I didn't mention this before."},{"Id":"1460648","PostId":"1595672","CreationDate":"2009-10-20T18:28:22.413","UserId":"193116","Body":"I understand that this is a cool technology. I want to know how are normal businesses using it. By Normal businesses , I mean non-google and non-facebook  type companies who have been using traditional  relational databases. \n\nI am looking for use cases or scenarios where people have leveraged this technology for &quot;normal&quot; businesses."},{"Id":"1460891","PostId":"1595672","CreationDate":"2009-10-20T19:06:34.287","UserId":"102937","Body":"See also Bigtable: http:\/\/jetfar.com\/bigtable-and-why-it-changes-everything\/ and http:\/\/labs.google.com\/papers\/bigtable.html"},{"Id":"1471421","PostId":"1604444","CreationDate":"2009-10-22T09:15:26.473","UserId":"105206","Body":"Yeah, but tell me please how to save and retreive my domain object in type safe manner?"},{"Id":"1486431","PostId":"1604444","CreationDate":"2009-10-24T21:55:29.740","UserId":"111332","Body":"i'm not sure exactly what you're looking for when you say &quot;type safety&quot;. i think the best you could do is use a database access layer that handles validating the data you're saving to and getting out of MongoDB."},{"Id":"1613760","PostId":"1342741","CreationDate":"2009-11-14T10:30:20.363","UserId":"162087","Body":"I'm interested in the way you have implemented the activity stream... Do you have suggestions on how to build the object model? I have posted a question about this (http:\/\/stackoverflow.com\/questions\/1443960\/how-to-implement-the-activity-stream-in-a-social-network) but i had not much luck.."},{"Id":"1615935","PostId":"1690853","CreationDate":"2009-11-14T22:14:48.500","UserId":"105206","Body":"Hi ,I've decided to use mongo in my project , but I don't know how to nest some object in my document, let's say i have question document and want to have answers in it , but have no idea how to do this"},{"Id":"1617454","PostId":"1737014","CreationDate":"2009-11-15T09:12:03.687","UserId":"90723","Body":"Documentum is one of the most vile pieces of overpriced enterprise software ever perpetrated."},{"Id":"1623473","PostId":"1690853","CreationDate":"2009-11-16T14:50:51.673","UserId":"2351","Body":"Embedded documents are just attributes on a containing document.  Here is a one liner.  You can certainly separate it out on multiple lines if need be.\nDocument doc = new Document().Append(&quot;embeddedDoc&quot;, new Document().Append(&quot;attr1&quot;,&quot;val1&quot;));"},{"Id":"1626890","PostId":"1690853","CreationDate":"2009-11-16T23:04:26.897","UserId":"105206","Body":"Ok, but is it possible to add collection of documents , let's say I have question and want have collection of answers for it, when i tried do this i had exception becouse key answers already exist"},{"Id":"1628616","PostId":"1744506","CreationDate":"2009-11-17T05:55:07.573","UserId":"78212","Body":"There are a few issues with the method as it stands, but using the property-space is probably one part of a solution so I'll give you an upvote! Thanks, Dmitry."},{"Id":"1639734","PostId":"1690853","CreationDate":"2009-11-18T15:43:06.647","UserId":"2351","Body":"Send me a message on GitHub with the code you are trying to do or post it to the mongodb-user Google group."},{"Id":"1650581","PostId":"1342741","CreationDate":"2009-11-19T20:47:22.563","UserId":"18424","Body":"@electroportal - I posted an answer on your question: http:\/\/stackoverflow.com\/questions\/1443960\/how-to-implement-the-activity-stream-in-a-social-network\/1766371#1766371"},{"Id":"1652097","PostId":"1512978","CreationDate":"2009-11-20T01:36:58.330","UserId":"51923","Body":"I thought that the 'automatic load balancing' issue raised above is important enough to warrant its own thread... which I started at http:\/\/stackoverflow.com\/questions\/1767789\/cassandra-load-balancing   \n\nthanks"},{"Id":"1658800","PostId":"667673","CreationDate":"2009-11-20T22:27:59.903","UserId":"175094","Body":"@le dorfier - Just because &quot;all the other web sites are doing it&quot; doesn't mean it's optimal.  I bet 99% of the 99% you were mentioning use an RDBMS because they don't know anything else."},{"Id":"1662843","PostId":"1777103","CreationDate":"2009-11-21T23:46:53.113","UserId":"139396","Body":"What will be the nature of the app? Or just any app?"},{"Id":"1664952","PostId":"1778782","CreationDate":"2009-11-22T15:10:27.960","UserId":"141346","Body":"Thanks. Googling this pattern seems to lead me to DDD most often of which I don't know much. Looks very interesting and already found some ideas that resonate with the direction I'm going."},{"Id":"1679580","PostId":"1777103","CreationDate":"2009-11-24T18:55:19.883","UserId":"51841","Body":"I was thinking it would be nice to have a plug-n-play dll which could be used to store objects to a file and query for them."},{"Id":"1703112","PostId":"1813745","CreationDate":"2009-11-28T21:17:54.963","UserId":"220599","Body":"Interesting, thanks! But how is security handled with a solution like this? Users of my system must log in to access data, and then they only can see certain data based on permissions that their account has."},{"Id":"1704486","PostId":"1813745","CreationDate":"2009-11-29T07:13:39.493","UserId":"2938","Body":"CouchApp is cool but I would say it is only for early-stage prototyping and experimentation. You will outgrow it; however it may become a part of your total application."},{"Id":"1707157","PostId":"1813612","CreationDate":"2009-11-29T23:34:53.770","UserId":"220599","Body":"Looked into Jersey and Restlets, but leaning toward Jersey. "},{"Id":"1707164","PostId":"1813745","CreationDate":"2009-11-29T23:36:44.217","UserId":"220599","Body":"So what do others who are using CouchApp do when they outgrow it?  From what I can tell, I would outgrow it from the start."},{"Id":"1707960","PostId":"1813745","CreationDate":"2009-11-30T04:25:13.310","UserId":"2140","Body":"Since CouchDB's API is RESTful, you can put any middleware you want in (I've seen successful Ruby and Python lightweight middleware). I'm sure  anything that can handle the JSON would be fine."},{"Id":"1712066","PostId":"1816191","CreationDate":"2009-11-30T19:06:27.500","UserId":"160104","Body":"I'll need to queries in this scenario, will I?\nOne for querying an index for Votes documents and one for getting the documents for User\/Story."},{"Id":"1712093","PostId":"1815943","CreationDate":"2009-11-30T19:10:08.040","UserId":"160104","Body":"Well, In fact I want to store more info in a Vote model. For example: created_at, ip, user_agent.\n\nShould I store the data in the stories list of users collection?"},{"Id":"1712835","PostId":"1815943","CreationDate":"2009-11-30T21:17:13.847","UserId":"111332","Body":"You could store the votes as an array of sub-documents, each like `{story_id: ..., created_at: ..., ip: ...}`, etc. Then the query becomes `find({'stories.story_id': ...})`. You can index on that, too."},{"Id":"1714119","PostId":"1816191","CreationDate":"2009-12-01T01:15:22.973","UserId":"32797","Body":"@Stanislav. That is correct. You'll first need to fetch the votes and then fetch users and\/or stories for those votes."},{"Id":"1714302","PostId":"1823568","CreationDate":"2009-12-01T02:05:16.010","UserId":"12349","Body":"&quot;JavaScript Injection&quot; is &quot;XSS&quot; or &quot;Cross-Site Scripting.&quot;"},{"Id":"1714328","PostId":"1823568","CreationDate":"2009-12-01T02:18:45.950","UserId":"55164","Body":"@Justice, you don't have to be cross site to inject JS, you can do it locally with an input feild"},{"Id":"1714710","PostId":"1823924","CreationDate":"2009-12-01T04:09:38.053","UserId":"34813","Body":"Isn't NOSQL a fancy way of saying that you are using either a flat file or a hashed table implemented maybe with a binary tree or any other type of classic data structures?\n\nThe concept of NOSQL is just: you don't need the functionality that comes with SQL (sumarization, selection, ordering, stored procedures, locking, etc.), so you can go without the overhead. You just use an old fashioned data structure that is optimized for your domain: insert speed, read speed, concurrency, etc.\n\nIf I'm not mistaken, you could call Python's Pickle NOSQL."},{"Id":"1715313","PostId":"1815943","CreationDate":"2009-12-01T07:01:08.410","UserId":"160104","Body":"Well I have a fairly big database with a few M records and will test the above scenario. "},{"Id":"1717440","PostId":"1823568","CreationDate":"2009-12-01T14:15:57.683","UserId":"99971","Body":"To be sure, @Justice, I had XSS in mind, but didn't mention it on purpose, because that's a whole other can of worms :)"},{"Id":"1735617","PostId":"1841979","CreationDate":"2009-12-03T19:44:49.940","UserId":"36590","Body":"ok, that makes a lot more sense then the way I was imagining it in my head. +1 clever trick to rebuild view."},{"Id":"1735877","PostId":"1841979","CreationDate":"2009-12-03T20:21:31.003","UserId":"2140","Body":"I believe recent versions of CouchDB (e.g. .10.1) use a has of the design document's view function to decide whether to rebuild the view. Thus, re-inserting the design document *may* not refresh the view. Certainly, updating with a new view function will, however."},{"Id":"1738915","PostId":"1841979","CreationDate":"2009-12-04T06:48:18.723","UserId":"2114","Body":"@barry, that's very interesting and it makes sense to. Do you have any links to where I could read more about view function hashes?"},{"Id":"1759116","PostId":"1852372","CreationDate":"2009-12-07T21:21:17.590","UserId":"30826","Body":"I knew about Digg and Facebook, but wasn't aware just how mature it was. Thanks!"},{"Id":"1787114","PostId":"1886659","CreationDate":"2009-12-11T08:43:24.590","UserId":"14955","Body":"It is an embedded DB though, I guess he was looking for a network-accessible solution."},{"Id":"1787132","PostId":"1886659","CreationDate":"2009-12-11T08:47:52.397","UserId":"71883","Body":"You can always use it in combination with a protocol like memcachedb (so memcache protocol but backed by berkeleydb)"},{"Id":"1787207","PostId":"1886659","CreationDate":"2009-12-11T09:08:09.593","UserId":"18548","Body":"Yes, I am looking at some network-accesible solution. Something that everybody on a team can connect to and work. Embedded dbs are fine as long as its on a dev system."},{"Id":"1787214","PostId":"1886658","CreationDate":"2009-12-11T09:09:28.983","UserId":"18548","Body":"Its not caching I am looking for. Its a datastore where I can store records instead of storing it in a database. "},{"Id":"1787387","PostId":"1813612","CreationDate":"2009-12-11T09:43:01.910","UserId":"124894","Body":"Why do you want to switch? What are those &quot;certain requirements&quot;? I'm curious. "},{"Id":"1787546","PostId":"1886659","CreationDate":"2009-12-11T10:11:05.530","UserId":"71883","Body":"ritesh: if you use memcachedb, then it is berkeley but accessible via the memcache protocol (so useable in a network)"},{"Id":"1795010","PostId":"1886679","CreationDate":"2009-12-12T13:51:12.713","UserId":"20578","Body":"\u201cFacebook uses Cassandra.\u201d Not to overstate the point, but that seems to soundly demolish the \u201cone of them seem to be ready for deployments on production like environments\u201d supposition."},{"Id":"1802047","PostId":"1893485","CreationDate":"2009-12-14T05:50:11.960","UserId":"18548","Body":"I totally agree. Especially given that you can manipulate the data (complicated stuff) and fields retrieved using SQL. You don't have to rely on a simple get(key) to retrieve. "},{"Id":"1802049","PostId":"1886650","CreationDate":"2009-12-14T05:51:15.983","UserId":"18548","Body":"I particularly liked this article. A good read if you are considering choosing the right nosql store option. http:\/\/www.eflorenzano.com\/blog\/post\/my-thoughts-nosql\/"},{"Id":"1802065","PostId":"1888750","CreationDate":"2009-12-14T05:55:07.860","UserId":"18548","Body":"The references are fantastic. Looks like there's a huge community backing Cassandra. I also love its distributed scaling feature. Cassandra it is !! "},{"Id":"1809224","PostId":"1902758","CreationDate":"2009-12-15T05:25:51.293","UserId":"18548","Body":"Very true. I did take a look at Neo4J and it looks great in terms of modeling relationships between entities. Thanks for the tip!!"},{"Id":"1809646","PostId":"1905688","CreationDate":"2009-12-15T07:18:33.297","UserId":"76337","Body":"Voted to close. This is a Q&amp;#38;A site, and  you've asked for a set of essays."},{"Id":"1813533","PostId":"1909110","CreationDate":"2009-12-15T18:00:08.710","UserId":"143804","Body":"Because it's soft, comfy and great for watching TV from?"},{"Id":"1813689","PostId":"1909110","CreationDate":"2009-12-15T18:25:35.397","UserId":"11181","Body":"I don't see anyone making a case for why this is anymore subjective than Why is C# suddenly so popular? http:\/\/stackoverflow.com\/questions\/575513\/why-is-c-suddenly-so-popular . Also, the questions was asked without pejoratives or all caps, so what is the case for labeling it argumentative?"},{"Id":"1814619","PostId":"1909110","CreationDate":"2009-12-15T20:24:49.210","UserId":"16587","Body":"@micahwittman You didn't see the poster's original question. Before I edited it he even included the word 'voldemort'. It was 1) silly 2) as asked, not a real question or at best subject and argumentative."},{"Id":"1814846","PostId":"299744","CreationDate":"2009-12-15T20:55:11.770","UserId":"152326","Body":"I am editing a quantity field of a product document. Then I must create thousands of &quot;tickets&quot; if quantity=2K for example. Then I reducing a quantity, I must delete some tickets. Sounds completely unrelaxed for me.\n\nA lot of headache in basic use cases. Maybe I am missing something, but why not bring back previously removed transaction behavior, just make it optional with something like _bulk_docs?reject_on_conflict=true. Quite useful in single-master configurations."},{"Id":"1817786","PostId":"1909110","CreationDate":"2009-12-16T06:13:56.367","UserId":"11181","Body":"George, I see - good call, then. Thanks."},{"Id":"1829045","PostId":"1512978","CreationDate":"2009-12-17T15:00:13.203","UserId":"130168","Body":"0.5 does do semiautomatic load balancing.  (The &quot;semi&quot; means an operator has to request it, but then Cassandra takes care of the rest.)  0.5 beta2 was released last week and an RC is coming soon."},{"Id":"1838370","PostId":"1928136","CreationDate":"2009-12-18T19:06:01.057","UserId":"53185","Body":"Thta mean that Mongo\/Tokyo not flush data to disk and have not recovery from crash??"},{"Id":"1842507","PostId":"299744","CreationDate":"2009-12-19T17:47:17.313","UserId":"35296","Body":"Bulk inserts for tickets doesn't seem like a huge deal to me.  Depending on your setup, you could just add a few tickets at a time and put more in as quantities change.\n\nYou'll likely need some sort of document per quantity reduction in any case.  If you reduce quantity because someone bought one, the ticket can also serve as a purchase record for that particular item.  Same goes for returns or most anything else that reduces quantity."},{"Id":"1845112","PostId":"1934092","CreationDate":"2009-12-20T14:07:36.307","UserId":"53185","Body":"Look better than mongo. Is sad, because mongo look easier to code, and the idea to use map reduce for everything.. yuck!. But data integrity is better..."},{"Id":"1845781","PostId":"1934092","CreationDate":"2009-12-20T18:24:10.287","UserId":"121199","Body":"I haven't tried Mongo yet. I do mainly web programming and CouchDB with json and the REST API is a perfect fit there.\n\nYou might need some time to get used to think your application in terms of documents and map reduce views, but then it becomes natural. \n\nAlso the user mailing list is very helpful if you need advise for design, view implementation, etc..."},{"Id":"1852538","PostId":"1928136","CreationDate":"2009-12-21T20:05:10.120","UserId":"36710","Body":"You can find at least some information about crashes and MongoDB here: http:\/\/www.mongodb.org\/display\/DOCS\/Durability+and+Repair"},{"Id":"1859177","PostId":"1813612","CreationDate":"2009-12-22T18:32:48.050","UserId":"220599","Body":"@Theo: actually, I do like the stack I've been using and plan to continue using it for some aspects.  But it isn't all that scalable, and I'm considering moving toward JSON\/REST to help with this.  Also, using wicket means passing HTML over the wire, and even with AJAX, this results in a lot more bandwidth usage than just passing JSON and letting the browser generate the HTML."},{"Id":"1859197","PostId":"1886912","CreationDate":"2009-12-22T18:36:33.863","UserId":"220599","Body":"Very good points, thanks!  I fully intend to use your suggestion to have the middleware act as just a proxy."},{"Id":"1859461","PostId":"1933173","CreationDate":"2009-12-22T19:18:01.640","UserId":"220599","Body":"Thanks! I haven't looked into cloudkit or persevere yet, so I'll spend some time with them. Your requirements are similar, needing security, workflows, rules, etc.\n\nI also need i18n and L10n and user-level customizations (themes\/layout\/etc). Theming can be handled client-side, but I don't want to do i18n on the client.  \n\nBecause my current stack already does much of this, I'm toying with letting it serve i18n'ed html that includes jquery code. The jquery would then function independently using JSON\/REST queries via Jersey. Migration from my current implementation might be simpler this way.\n"},{"Id":"1866981","PostId":"1813612","CreationDate":"2009-12-23T19:54:40.130","UserId":"220599","Body":"I'm pretty new to SO, so I'm unclear on why someone would downvote my question. Doesn't it cost rep to down vote? Would it be because I haven't selected an answer yet?  Or is my question flawed in some way? Oh well..."},{"Id":"1869287","PostId":"1954804","CreationDate":"2009-12-24T04:56:05.283","UserId":"223370","Body":"Awesome. Thanks, this is what I was hoping to hear."},{"Id":"1872708","PostId":"1959820","CreationDate":"2009-12-24T21:41:16.607","UserId":"69307","Body":"Strange then that data warehousing tools (which deal with truly gigantic datasets - every item sold by Walnart, for example)  have provided such facilities for years. And is &quot;scalable database&quot; the new euphemism for &quot;databases for dimwits&quot;? "},{"Id":"1874591","PostId":"1961090","CreationDate":"2009-12-25T16:18:02.713","UserId":"70293","Body":"It is hard to write code to handle all versions of the documents. Code evolves and database should evolve too.\n\nSuch databases are not schemaless, they are schema free. And this mean that you could have some document structures but there are no strong restrictions."},{"Id":"1874597","PostId":"1961090","CreationDate":"2009-12-25T16:20:02.867","UserId":"70293","Body":"I think that for NoSQL databases we've to have &quot;data migration&quot; tools, rather then &quot;schema migration&quot; tools. If there isn't any, then I'll write one myself."},{"Id":"1876657","PostId":"1960570","CreationDate":"2009-12-26T11:25:01.390","UserId":"42151","Body":"ruby driver is not that fast especially 1.8 but 1.9 just boosts the performance!\ni am just wondering if mongoid is more optimized or the only thing it offers is a different approach to quering and stuff\nfor the time being mongomapper is almost feature complete offering almost all AR sugar"},{"Id":"1877103","PostId":"1961090","CreationDate":"2009-12-26T15:25:16.363","UserId":"14343","Body":"I'm not sure what the distinction is between &quot;schemaless&quot; and &quot;schema free&quot;.  In any case, one advantage of these databases is that you don't have to update all of the data when the schema changes.  You could, for example, update each record\/document as it is read and discovered to be in an old format.  If you don't find any tools that do what you want, you are either blazing a new trail, or not understanding the NoSQL culture."},{"Id":"1879727","PostId":"1961090","CreationDate":"2009-12-27T13:07:56.633","UserId":"70293","Body":"Ok. To update data to a new version I need a tool anyway. In my opinion, it is more convinient then to have code which will work with all versions of the the documents.\n\nAre you really don't understand difference between schemaless and schema-free? :-)"},{"Id":"1880340","PostId":"1961013","CreationDate":"2009-12-27T17:41:46.350","UserId":"25450","Body":"The question is how one emulates relational features in NoSQL? For example, what's the right way to do many-to-many relations in key-value storage? Or constraints? Welcome to SO, BTW :-)"},{"Id":"1882789","PostId":"1961013","CreationDate":"2009-12-28T09:13:31.457","UserId":"70293","Body":"No. I mean schema migration. How to migrate from one document version to another (rename fields, etc.)."},{"Id":"1882794","PostId":"1968612","CreationDate":"2009-12-28T09:14:42.937","UserId":"239472","Body":"I'm interested in the question of how to design a system that may have millions of users, with content visibility defined by friend relationships.  How is that done?  Whether or not the site is a commercial success is beside the point at this stage. "},{"Id":"1882797","PostId":"1966375","CreationDate":"2009-12-28T09:15:24.357","UserId":"70293","Body":"Hm, this make a sense. But question is about ready tools, which will help me too keep my document versions up to date."},{"Id":"1882861","PostId":"1968589","CreationDate":"2009-12-28T09:42:15.783","UserId":"164394","Body":"Looking at your comment below &quot;how to design a system that may have millions of users&quot; is not confined to social web sites but to any heavily used sites. Amazon, Google, Yahoo, Microsoft etc. By searching the net and reading at case studies about these sites you will learn as much."},{"Id":"1901789","PostId":"1985382","CreationDate":"2009-12-31T13:48:11.587","UserId":"4093","Body":"I'm not looking for a spesific type of database. I have looked at document-oriented databases and objcet databases. I don't want to acheve something spesific, but I want to learn about a &quot;new&quot; way to persist data. If I'm going to learn about a new database, I want to learn about the one that is most mature at the moment."},{"Id":"1901883","PostId":"1985382","CreationDate":"2009-12-31T14:11:28.483","UserId":"235058","Body":"That's kind of my point though...mature to what purpose?"},{"Id":"1902095","PostId":"1985382","CreationDate":"2009-12-31T14:57:52.117","UserId":"4093","Body":"MongoDb, for example, supports indexes and has some functionality that can't be found in couchdb. I might be wrong, but I consider MongoDB to be more mature that couchdb. When looking at the .NET drivers for MongoDB they are still under development, and I consider them to not be that mature. For simplicities\u2019 sake I can rephrase the question to; what is the best choice when going for document-oriented databases on the windows platform?"},{"Id":"1902307","PostId":"1985382","CreationDate":"2009-12-31T15:45:31.053","UserId":"235058","Body":"Thanks for bearing with me. Indeed, confining the question to document databases is much more helpful then using the generic NoSQL tag. Thanks :)\n\nYou mention that MongoDB has indexes and some functionality that can't be found in Couchdb. But Couchdb has more advanced replication, ACID compliance and javascript views. So again, it's a matter of what you want to do that determines your choice. \n\nI don't want to hold you longer than necessary. I mean, I am not a NoSQL\/doc database expert. My point is just, refine your question, get better answers"},{"Id":"1914431","PostId":"1995216","CreationDate":"2010-01-03T20:02:45.293","UserId":"27535","Body":"You want a *SQL* JOIN or UNION  operation in a product called *NoSQL*?"},{"Id":"1916282","PostId":"1996579","CreationDate":"2010-01-04T05:36:39.477","UserId":"27535","Body":"+1 well said..."},{"Id":"1933766","PostId":"2012900","CreationDate":"2010-01-06T12:37:57.143","UserId":"20972","Body":"What's wrong with json or yaml?"},{"Id":"1933821","PostId":"2012900","CreationDate":"2010-01-06T12:46:15.193","UserId":"89391","Body":".. http:\/\/www.trentrichardson.com\/jsonsql\/"},{"Id":"1933966","PostId":"2013057","CreationDate":"2010-01-06T13:11:00.320","UserId":"166921","Body":"I like the ideas of CouchDB. Especially how indexes are built but I'm seeking something that is to CouchDB as Sqlite is to MySql"},{"Id":"1933983","PostId":"2012949","CreationDate":"2010-01-06T13:14:03.280","UserId":"166921","Body":"xml is good enough, but I need something that could be used especially from php and python"},{"Id":"1934849","PostId":"2013012","CreationDate":"2010-01-06T15:13:38.547","UserId":"52210","Body":"You're thinking of `qawk`, which can be found at http:\/\/cm.bell-labs.com\/cm\/cs\/awkbook\/ as the examples.  I suggest downloading the .txt version which, of course, is an awk script that auto-extracts all the examples from the book.  The clever thing about `qawk` was that tables were stored in flat files (with field names as the first line) and qawk would automatically do joins to generate a table that contained every field name in your query.  I suspect it's not really what's being looked for, but it's a classic bit of Bell Labs smart-guy software."},{"Id":"1942818","PostId":"2013806","CreationDate":"2010-01-07T14:20:11.840","UserId":"166921","Body":"Memory and speed are constraints because I want to use it in web application reading some records at each requests. I don't want to share memory across requests so script servicing each request is on is own and should not grab too much memory (even few megs might be too much).\n\nThunderbird is nice example. There is a flat data file and index file taht allows for fast access. If index file is corrupted or out of date you can simply delete it and have it regenerated."},{"Id":"1950693","PostId":"2013806","CreationDate":"2010-01-08T12:55:10.190","UserId":"15459","Body":"OK, I was thinking of desktop applications instead. Your arguments are convincing.\nMongoDB mentioned by valya seems adapted to Web applications (most or all of featured applications are Web app) but it still uses a binary storage, if I understood correctly.\nAn alternative (a bit clumsy) is to export DB content for versioning purpose, and perhaps for merge (to re-import later). Might be problematic with a server in production usage..."},{"Id":"1950737","PostId":"2013806","CreationDate":"2010-01-08T13:00:36.750","UserId":"15459","Body":"[Mimesis](http:\/\/mimesis.110mb.com\/ &quot;Mimesis&quot;) mentioned in the Wikipedia article is a textual database written in PHP. Might be what you are looking for. If PHP is an option for you (you haven't mentioned a language...)."},{"Id":"1968330","PostId":"1997069","CreationDate":"2010-01-11T14:50:53.357","UserId":"148146","Body":"Do they really use a key-value store as their main database? While Amazon Web Services offers SimpleDB to the public (a key-value datastore), that doesn\u2019t mean they use it exclusively for their internal needs."},{"Id":"1968334","PostId":"1997069","CreationDate":"2010-01-11T14:51:20.830","UserId":"47281","Body":"Good question - I'm not sure!"},{"Id":"1974366","PostId":"2045418","CreationDate":"2010-01-12T07:47:19.070","UserId":"55408","Body":"peter, thanks for the answer. I'll look into it and accept your answer if nobody else responds."},{"Id":"2011719","PostId":"1995372","CreationDate":"2010-01-17T11:06:39.683","UserId":"55408","Body":"+1 for the funny video"},{"Id":"2012099","PostId":"2081090","CreationDate":"2010-01-17T13:44:25.543","UserId":"55408","Body":"If I understand you correctly, this would mean all the data would have to be loaded into memory, which is not an option (too much data). I want to be able to access data from the disk on an individual record basis."},{"Id":"2012182","PostId":"2081090","CreationDate":"2010-01-17T14:09:20.000","UserId":"47550","Body":"That's correct. i thought the size of your data might be smaller the way you were describing it."},{"Id":"2012381","PostId":"2081090","CreationDate":"2010-01-17T15:04:18.450","UserId":"55408","Body":"I've updated the question. Anyway, if it could all fit into memory, I probably wouldn't really need a data store in the first place - I could simply binary serialize all the data objects into a file."},{"Id":"2012540","PostId":"2081415","CreationDate":"2010-01-17T15:46:37.903","UserId":"227803","Body":"But he wanted a schema-less store...."},{"Id":"2012620","PostId":"2081415","CreationDate":"2010-01-17T16:03:44.663","UserId":"55408","Body":"Astor is right: I want to avoid the relational model. I want to be able to store practically any kind of data without first having to prepare the database schema for it. Also, having a strict relational model can be problematic if the data structure changes later - I would need to write SQL change scripts for the existing data in the store."},{"Id":"2012711","PostId":"2081415","CreationDate":"2010-01-17T16:25:53.273","UserId":"128709","Body":"I know what he is looking for but such tools like NHibernate with schema generation hide the relational aspect nearly completely. You do not need to define any schema but only the mapping for you classes (which is really straight forward with Fluent NHibernate) and when your classes change, you will need to do some kind of update in any persistence strategy."},{"Id":"2012790","PostId":"2081415","CreationDate":"2010-01-17T16:47:02.753","UserId":"55408","Body":"I appreciate that, but hiding relational aspects isn't the same as not having relational model at all. And in practice this hiding goes only so far - sooner or later you need to deal with it &quot;manually&quot; (like in the case of the changes in the model). On the other hand, if you store the data as documents (which some NoSQL solutions do), you don't really need to update the old data - you just need to make sure you support the reading of the data in the older form."},{"Id":"2014760","PostId":"2081578","CreationDate":"2010-01-18T00:18:33.767","UserId":"26444","Body":"Ad 1: Faceted search\/navigation per se isn't my priority, I may use regular &quot;advanced search&quot; form with different input data types (strings, prices, ranges etc). I was just thinking whether facets could help in achieving flexibility. \n\n\nAd 2: What is data and what is schema depends on an point of view. In EAV everything is data, OTOH if I choose to use &quot;resolution&quot; as a column it becomes schema. If I want to add new attribute type to the TVs category (eg. number of USB ports) it may as well be described as schema change.\n\n\nad 4. Interesting, do you know any examples of that? \n\n\n"},{"Id":"2014826","PostId":"2081578","CreationDate":"2010-01-18T00:39:45.053","UserId":"21239","Body":"1. If you wanted to have hierarchical categories, then no, it won't be easy with Solr because of 5. \n2. I admit it's subjective, but IMO if you have to generate code to accomodate a new category, then it's a schema change, not a data change, to your application. \n4. any crawler-based app, e.g. Google or http:\/\/www.lucidimagination.com\/About-Search . "},{"Id":"2073232","PostId":"2059509","CreationDate":"2010-01-25T16:41:57.857","UserId":"220599","Body":"Thanks Kris, I'll check out Pintura."},{"Id":"2080889","PostId":"2140228","CreationDate":"2010-01-26T15:12:57.487","UserId":"50676","Body":"yeah i know about sqllite and bdb. But i'm not sure if rdbms will fit into my case. Because my major purpose here is to archive the data. I will not perform complex queries. also the vertical scalability of couchdb also look appealing. But this option that you have mentioned is still in my mind."},{"Id":"2080898","PostId":"2140200","CreationDate":"2010-01-26T15:14:26.953","UserId":"50676","Body":"Does it have a C api and can you provide me some benchmark info related to this."},{"Id":"2080979","PostId":"2140228","CreationDate":"2010-01-26T15:23:05.587","UserId":"206367","Body":"@holydiver: look in here...at the other SO question...http:\/\/stackoverflow.com\/questions\/417917\/alternatives-to-sqlite"},{"Id":"2080999","PostId":"2140200","CreationDate":"2010-01-26T15:25:04.947","UserId":"220825","Body":"It's written in C and has an excellent API. You can read the benchmarks here: http:\/\/1978th.net\/tokyocabinet\/benchmark.pdf"},{"Id":"2081326","PostId":"2140125","CreationDate":"2010-01-26T16:08:14.410","UserId":"231458","Body":"Thanks kb - have gone with the collection on its own, seems to be working okay so far; just need to stress test it a bit."},{"Id":"2082622","PostId":"2140125","CreationDate":"2010-01-26T18:35:02.883","UserId":"215860","Body":"Cool. It should still be efficient."},{"Id":"2084636","PostId":"1959835","CreationDate":"2010-01-26T22:47:41.273","UserId":"105938","Body":"On Mac, there's also CouchDBX (http:\/\/janl.github.com\/couchdbx\/) which basically wraps the web-based front-end in a stand-alone app. It's an nicely polished database front-end, especially considering it's in the browser."},{"Id":"2085906","PostId":"2144344","CreationDate":"2010-01-27T03:17:23.837","UserId":"76337","Body":"SQL Server 2008 is an example of a database that can do both (using the FILESTREAM datatype)."},{"Id":"2086172","PostId":"2144344","CreationDate":"2010-01-27T04:20:03.230","UserId":"46571","Body":"Wow. Awesome feature. (I've never used SQL Server 2008.)"},{"Id":"2086182","PostId":"1118594","CreationDate":"2010-01-27T04:22:20.213","UserId":"46571","Body":"To develop a transactional app, there's always a need to normalize data to some degree. Either the third NF or the Boyce-Codd NF are usually good compromises between the effort required to normalize data and the effort required to maintain data consistency when it's not normalized enough."},{"Id":"2086186","PostId":"337861","CreationDate":"2010-01-27T04:24:57.807","UserId":"46571","Body":"@Matt, data normalization is just a tool. The degree to which you normalize data is a tradeoff between database design effort and consistency maintenance effort."},{"Id":"2086502","PostId":"2144279","CreationDate":"2010-01-27T05:52:59.913","UserId":"46571","Body":"Uh, don't copy-paste from Wikipedia (or any other source), explicitly quote it. Trying to pass something someone else came up with as the product of your own work is inherently dishonest."},{"Id":"2087357","PostId":"2140200","CreationDate":"2010-01-27T09:28:50.167","UserId":"50676","Body":"wow results are pretty awesome, i'm currently testing tokyo cabinet. Also from the document you have sent cdb's performance looks appealing too. What are the major benefits of tokyodb over cdb?"},{"Id":"2087372","PostId":"2144765","CreationDate":"2010-01-27T09:30:13.720","UserId":"50676","Body":"yes actually it supports offline data. but couchdb is pretty slow when compared to other options."},{"Id":"2092522","PostId":"2140200","CreationDate":"2010-01-27T20:28:08.793","UserId":"220825","Body":"I prefer TC because it is  maintained, has full-text search extensions, and has excellent packages for other languages. If these things aren't that important then cdb might be a viable alternative (I've not actually used it so I can't say how it stacks up against TC in the real world). Good Luck!"},{"Id":"2100389","PostId":"1189911","CreationDate":"2010-01-28T18:36:12.953","UserId":"37539","Body":"FYI, I've written a long-form report on this topic, here: http:\/\/www.google.com\/url?sa=D&amp;#38;q=http:\/\/ianvarley.com\/UT\/MR\/Varley_MastersReport_Full_2009-08-07.pdf&amp;#38;usg=AFQjCNEbAclrEmzOeefIjj2dG_IgaoBmdQ\n\nThanks to all of you for your helpful input!"},{"Id":"2109390","PostId":"2144765","CreationDate":"2010-01-29T20:05:18.073","UserId":"234031","Body":"i know of couchdb databases with many terabytes and lots of indexes running plenty fast for lots of concurrent users.\n\nmost of the MongoDB benchmarks (for writes) are a little misleading since insert() calls in MongoDB don't return a response and aren't guaranteed to be written to disc or even accessible. MongoDB write benchmarks seem to mostly test socket.write() times :)"},{"Id":"2118252","PostId":"2172261","CreationDate":"2010-01-31T16:47:54.857","UserId":"88054","Body":"I never said I wanted to build something to follow something else. I was looking for best patterns you have successfully used to make things work best together. Ideally, with PHP 5.3's features. Also, I am not looking for advices as whether to use relational or document-oriented DBs."},{"Id":"2119036","PostId":"2173082","CreationDate":"2010-01-31T19:57:36.023","UserId":"199397","Body":"community wiki?"},{"Id":"2119047","PostId":"2173082","CreationDate":"2010-01-31T19:59:19.243","UserId":"21234","Body":"http:\/\/en.wikipedia.org\/wiki\/Nosql ???"},{"Id":"2119063","PostId":"2173090","CreationDate":"2010-01-31T20:04:11.170","UserId":"257942","Body":"thanks for the answer!"},{"Id":"2119179","PostId":"2173158","CreationDate":"2010-01-31T20:31:11.573","UserId":"257942","Body":"interesting. thanks for contributing your answer."},{"Id":"2119217","PostId":"2173089","CreationDate":"2010-01-31T20:38:43.257","UserId":"257942","Body":"i have a better understanding now. thank you!"},{"Id":"2119644","PostId":"2173089","CreationDate":"2010-01-31T21:57:36.180","UserId":"164255","Body":"The original impetus for these new approaches is horizontal scalability, but other benefits are now significantly, mainly ease of development.  Document-oriented databases for example eliminate a lot of the object-relational 'impedance mismatch' work of the past.  Also the flexible schemas here fit well with the newer dynamically typed programming languages (Python, Ruby, PHP, ...)"},{"Id":"2123718","PostId":"2177226","CreationDate":"2010-02-01T14:27:50.847","UserId":"88054","Body":"You're right: it's too early, just as I thought too. +1, but I'll be waiting for a while for other opinions too."},{"Id":"2123818","PostId":"2177226","CreationDate":"2010-02-01T14:40:34.987","UserId":"88054","Body":"As I can see it soo far, it strongly depends on the operations you intend to do on the data and how often the application would do those operations under normal circumstances. For instance, embeding comments into a &quot;post&quot; would not be best if the app would put in place a functionality to &quot;stalk&quot; a specific person (like &quot;tweets&quot;)."},{"Id":"2124351","PostId":"2177226","CreationDate":"2010-02-01T15:42:42.477","UserId":"6844","Body":"For sure. I think any best-practices which do emerge will be predicated on the way the data is to be made use of. Different decisions and compromises should be made in order to best accommodate those requirements."},{"Id":"2156668","PostId":"2162858","CreationDate":"2010-02-05T07:38:47.403","UserId":"190822","Body":"Do you have any step by step instructions I could follow to get Riak onto windows?"},{"Id":"2164377","PostId":"2212230","CreationDate":"2010-02-06T05:57:45.137","UserId":"138026","Body":"FYI... NoSQL databases are still DBs, they are just not relational.\n\nAs to the transactions, A transaction is simply the logical grouping of queries and updates. Non-Relational DBs still provide both of those functions. What kind of things are sensitive to what things?"},{"Id":"2164401","PostId":"2212230","CreationDate":"2010-02-06T06:10:07.713","UserId":"101823","Body":"well, i want to do money transactions, or at least think about them.  but i still want some integrity in that sense."},{"Id":"2164421","PostId":"2212230","CreationDate":"2010-02-06T06:17:55.827","UserId":"27535","Body":"How many terabytes of data do you have that you can't use a standard, mainstream RDBMS that has built-in transaction support?"},{"Id":"2184985","PostId":"2229880","CreationDate":"2010-02-09T15:05:19.787","UserId":"111124","Body":"+1 Definately needs the staff \/ personnel to deal at the high end."},{"Id":"2186156","PostId":"1799958","CreationDate":"2010-02-09T17:14:27.593","UserId":"190822","Body":"Did you ever get Riak installed on Windows? I am interested in doing the same."},{"Id":"2186679","PostId":"2229420","CreationDate":"2010-02-09T18:20:50.813","UserId":"36710","Body":"It would be easier to provide a useful answer if you add some information on the domain or the structure of the data and queries you are dealing with."},{"Id":"2194451","PostId":"2232849","CreationDate":"2010-02-10T16:04:19.027","UserId":"124894","Body":"I think we are talking here about a many-to-many-to-many relationship not a many-to-many relationship. Each car type has lots of features and each shop can sell many car types. "},{"Id":"2208475","PostId":"2247790","CreationDate":"2010-02-12T06:05:21.957","UserId":"190822","Body":"Which key-value datastores do you currently have drivers for?"},{"Id":"2212516","PostId":"2248697","CreationDate":"2010-02-12T17:03:23.313","UserId":"190822","Body":"Are there any projects which actually have drivers available for them?"},{"Id":"2219489","PostId":"2251556","CreationDate":"2010-02-13T21:55:04.810","UserId":"34819","Body":"thank you - i realize that with the MongoDB Driver and the above PHP tutorial i can make it all happen."},{"Id":"2220112","PostId":"2259703","CreationDate":"2010-02-14T00:40:52.183","UserId":"20862","Body":"I'd suggest Fedora, but I haven't actually used any of those on it in anger."},{"Id":"2220116","PostId":"2259703","CreationDate":"2010-02-14T00:41:45.150","UserId":"47773","Body":"You're basically asking &quot;What's the best distro for programming&quot;?  This is just as contentious (and talked to death) as the editor wars.  See http:\/\/stackoverflow.com\/questions\/404520\/best-linux-distribution-for-programming-closed for past discussion.  It's also probably more appropriate on superuser."},{"Id":"2220135","PostId":"2259703","CreationDate":"2010-02-14T00:46:30.210","UserId":"3225","Body":"Mono and openSuse are always up to date. Since Novel where Miguel works on Mono and Suse is distributed from. "},{"Id":"2220758","PostId":"2259852","CreationDate":"2010-02-14T05:00:26.023","UserId":"52360","Body":"@DigitalRoss thanks for the info! So I don't really want to start any religious wars here, but which desktop do you prefer out of Gnome and KDE. I will go and do some research but it is always good hearing different opinions :)"},{"Id":"2222412","PostId":"2251556","CreationDate":"2010-02-14T15:40:38.237","UserId":"124378","Body":"If you create a good library please share it with the community. Id love an excuse to play with MongoDB. :-)"},{"Id":"2222515","PostId":"2248697","CreationDate":"2010-02-14T16:11:19.663","UserId":"36710","Body":"There's drivers for RDF+SAIL, Neo4j and MongoDB AFAIK. You'd better ask on the Gremlin mailing list, I can't keep track of everything happening over there at the moment!"},{"Id":"2226770","PostId":"2261118","CreationDate":"2010-02-15T11:11:12.743","UserId":"52360","Body":"Awesome thanks for the heads up on the C# redis client that looks cool! Doesn't ruby run pretty slow on windows?"},{"Id":"2226980","PostId":"2261118","CreationDate":"2010-02-15T11:49:55.100","UserId":"85785","Body":"It used to. Ruby 1.9.x and Iron Ruby are now a lot faster: http:\/\/antoniocangiano.com\/2009\/08\/03\/performance-of-ironruby-ruby-on-windows\/\n"},{"Id":"2229804","PostId":"2251556","CreationDate":"2010-02-15T19:08:20.643","UserId":"34819","Body":"@Phil Sturgeon - looks like @stephenc beat me to it."},{"Id":"2229812","PostId":"2268101","CreationDate":"2010-02-15T19:08:45.387","UserId":"34819","Body":"thank you very much. Very good start."},{"Id":"2233682","PostId":"2251556","CreationDate":"2010-02-16T09:11:29.437","UserId":"124378","Body":"Sweet, I only wish I had the time to make one myself. :-) Looks cool."},{"Id":"2234314","PostId":"2162858","CreationDate":"2010-02-16T11:06:54.830","UserId":"190822","Body":"Ok, I am going to try this now"},{"Id":"2249069","PostId":"2278263","CreationDate":"2010-02-17T23:44:39.620","UserId":"164255","Body":"CDN plus a NoSQL db as the origin is a great combination.  I have seen this done a couple times with MongoDB (and its GridFS module) successfully."},{"Id":"2251198","PostId":"2278219","CreationDate":"2010-02-18T08:44:14.847","UserId":"72356","Body":"Thanks, I'll check it out"},{"Id":"2256682","PostId":"1690853","CreationDate":"2010-02-18T21:36:36.953","UserId":"3797","Body":"Does Mongo only works as dictionary. I mean what if I have a User class with FirstName and LastName properties. "},{"Id":"2262846","PostId":"2297244","CreationDate":"2010-02-19T16:40:21.803","UserId":"28287","Body":"Thanks for the info. This is what I was hoping. My app is very write-heavy and most of the time, other users that care about oft-written data are going to be long-polling or equivalent and will be pushed the data. Thus, the number of reads will be minimal.\n\nIf I go the quorum-writes route I suppose I should always provision an odd number of instances for my Cassandra cluster, yes?"},{"Id":"2265295","PostId":"2297244","CreationDate":"2010-02-19T22:07:18.357","UserId":"130168","Body":"quorum is a function of replication factor, not total node count.  so your minimum number of nodes (=RF) will be odd but growing past that does not need to be."},{"Id":"2266416","PostId":"2297244","CreationDate":"2010-02-20T03:35:47.987","UserId":"28287","Body":"Oh, OK. An example. I could have 1000 nodes in my cluster, but a replication factor of 5.  Quorum would be 5\/2+1=3.  Thus, as long as 3 nodes were contacted\/written\/etc successfully then all is considered successful?"},{"Id":"2271071","PostId":"2297244","CreationDate":"2010-02-21T05:27:49.687","UserId":"130168","Body":"That is correct."},{"Id":"2271163","PostId":"2268101","CreationDate":"2010-02-21T06:05:09.050","UserId":"34819","Body":"Stephen\n\nWhat about models? Is there any special consideration that has to be given there?"},{"Id":"2272028","PostId":"2287361","CreationDate":"2010-02-21T11:52:27.603","UserId":"13724","Body":"A C# provider is mostly irrelevant, as these systems do NOT have an interface which looks anything like a conventional database (hence &quot;NoSQL&quot;) so an ADO.NET interface would be a round peg into a square hole."},{"Id":"2274487","PostId":"2268101","CreationDate":"2010-02-21T22:28:31.147","UserId":"34819","Body":"I was able to get the models functionality working also. Nothing special, still inherit from Model and your functions just have to call Mongo specific functions. Easy"},{"Id":"2284893","PostId":"2316921","CreationDate":"2010-02-23T09:22:43.970","UserId":"68457","Body":"What where the two databases in question (sql and NoSQL)?"},{"Id":"2284956","PostId":"2316921","CreationDate":"2010-02-23T09:34:13.130","UserId":"277084","Body":"Both were MySQL (I've edited my response to provide this info, I forgot it initially).  Same DB, very different performance results from the SQL and NoSQL approaches. Very happy with key\/value approach with MySQL."},{"Id":"2285363","PostId":"2287361","CreationDate":"2010-02-23T10:51:00.870","UserId":"124894","Body":"Indeed you don't need an provider that implements the ADO.NET interface but you still need some kind of driver\/provider to couple between the db and .NET . There is one for MongoDB but it isn't perfect yet. The exception handling for instance needs improvement. "},{"Id":"2285856","PostId":"2315815","CreationDate":"2010-02-23T12:06:28.647","UserId":"55408","Body":"Nice approach, although I feel using files for storing values would be a bit over-the-top for simple values (a single integer, for example)."},{"Id":"2285873","PostId":"2315450","CreationDate":"2010-02-23T12:09:07.457","UserId":"55408","Body":"@Laurion, I've seen ESENT and was initially very excited. The only problem is that it's Windows-only (think Mono + Linux\/Mac)."},{"Id":"2291734","PostId":"2285045","CreationDate":"2010-02-23T23:36:19.673","UserId":"45935","Body":"+1: A great question given all the press NoSQL has been getting.  "},{"Id":"2292520","PostId":"2315815","CreationDate":"2010-02-24T02:26:15.273","UserId":"38207","Body":"The question sort of implies that what is being stored can be quiet large (documents \/ too much data to be loaded into memory). One of the advantages of the file approach is that you get a nice set of Stream handling classes for free, which is very useful when dealing with big chunks of data and much cleaner than for example splitting data into arbitary nMB blobs and storing it in a database. "},{"Id":"2296310","PostId":"2316921","CreationDate":"2010-02-24T14:42:12.313","UserId":"106396","Body":"Hi Brian, would it be possible to provide an example of the schema of your normalised structure and an example of the key-value pairs &quot;schema&quot;? We are also facing performance issues with a normalised structure and are currently considering two options: either denormalising our tables or moving towards a NoSQL data store. Due to the licensing and maintenance fees we are already paying, we would like to leverage on our current Oracle stack and therefore, are leaning towards a denormalised RDBMS solution. An example would be interesting!"},{"Id":"2297690","PostId":"2322677","CreationDate":"2010-02-24T17:19:25.923","UserId":"276138","Body":"You should also read http:\/\/cacm.acm.org\/magazines\/2010\/1\/55744-mapreduce-a-flexible-data-processing-tool\/fulltext"},{"Id":"2297766","PostId":"2315815","CreationDate":"2010-02-24T17:28:26.673","UserId":"55408","Body":"True. What about physical limits of the file system? How would such store behave when the number of records reaches &gt; 100.000?\n\nAlso: when I talked about &quot;too much data&quot;, I meant the _whole_ database - I mentioned this to avoid answers like object tree serialization and similar."},{"Id":"2298760","PostId":"2316921","CreationDate":"2010-02-24T19:41:11.750","UserId":"4435","Body":"@Brian: Since 4 of the examples are written IN java, which Java support features were missing or immature? I have no experience in this field, but that seems slightly surprising to me."},{"Id":"2300146","PostId":"2316921","CreationDate":"2010-02-24T22:12:04.957","UserId":"277084","Body":"tthong - not sure how to concisely include our normalised schema but I've added an example of how we store our content in a single text field. It's a little contrived, I've not been able to include a real example as my boss'd go ballistic so any &quot;problems&quot; with this &quot;data model&quot; are most likely for that reason. I would advise benchmarking both Oracle and some other solutions, but if your organisation has good Oracle expertise, DBAs, backups, etc, it could be a really good option to consider"},{"Id":"2300186","PostId":"2316921","CreationDate":"2010-02-24T22:16:03.870","UserId":"277084","Body":"Jimmy - apologies for the confusion, I meant to say that immature Java support was an example of what we found. Other factors influenced us, e.g. we need an embedded option, we need a zero-cost solution for our distribution model (rules out BerkeleyDB, Neo4j, plus other sound tech choices). Generally, a key\/value approach in an otherwise SQL model was the only thing to tick all our boxes."},{"Id":"2300399","PostId":"2285045","CreationDate":"2010-02-24T22:47:18.787","UserId":"70157","Body":"How is this a bounty question? What constitutes a single correct answer to this question?"},{"Id":"2303118","PostId":"2268101","CreationDate":"2010-02-25T09:13:02.130","UserId":"155862","Body":"Exactly.  You should be able to go $this-&gt;mongo-&gt;db directly in your model code."},{"Id":"2304749","PostId":"2322677","CreationDate":"2010-02-25T13:38:52.493","UserId":"45935","Body":"@ar: Thanks, that's a good link.  The Vertica folks have generated a fair amount of controversy."},{"Id":"2304894","PostId":"2316921","CreationDate":"2010-02-25T13:57:19.513","UserId":"124894","Body":"@tthong, instead of storing the properties in a single text field, you can use an xmltype column in Oracle for storing an xml document. Oracle has rich xml possibilities. Using an xmltype can be a good compromise between a single text field and normalized relational storage. Oracle can index the elements in your xml document so it is possible to search on an element in your xml document without full table scans. You loose this possibility when you use a single text field. "},{"Id":"2305134","PostId":"2285045","CreationDate":"2010-02-25T14:24:12.510","UserId":"58394","Body":"bignose: I view the bounty as my 550 reputation tip given to the person providing the most informative answer :-)"},{"Id":"2306118","PostId":"2335045","CreationDate":"2010-02-25T16:02:28.687","UserId":"28287","Body":"Nice. Do you know of any other similar exercises? I am not finding (m)any."},{"Id":"2306394","PostId":"2316921","CreationDate":"2010-02-25T16:30:44.207","UserId":"105662","Body":"How do you efficiently find all products that have a foul flavor?"},{"Id":"2306474","PostId":"2316921","CreationDate":"2010-02-25T16:40:37.290","UserId":"124894","Body":"@hobodave, I think that that is impossible when you store your data in a single text field. Reporting becomes also hard. "},{"Id":"2306641","PostId":"2316921","CreationDate":"2010-02-25T16:56:29.700","UserId":"105662","Body":"@Theo: It's not impossible, there are solutions (Sphinx). My question is directed at Brian. I want to know how he does it in his application."},{"Id":"2306671","PostId":"2316921","CreationDate":"2010-02-25T16:59:36.540","UserId":"105662","Body":"@Brian: I'm assuming (perhaps incorrectly) that both Product2 and Product3 exist as first level products as well, thus they're duplicated. If this is the case, how do you handle updates to product information?"},{"Id":"2306696","PostId":"2316921","CreationDate":"2010-02-25T17:02:01.527","UserId":"277084","Body":"Theo - indeed we tried XML too. It so happened it wasn't fast enough for our liking, but it's a good option where it meets peoples' needs."},{"Id":"2306755","PostId":"2316921","CreationDate":"2010-02-25T17:07:34.383","UserId":"277084","Body":"Hobodave - a weakness of my illustration, but the child content is &quot;proper&quot; child content, not references to sibling content. And you have identified the main trade-off of a big text chunk: the sort of reporting you mention, finding all foul tasting products, would be hard. We don't need to do that but it's a very important concession for other folks who might be considering such a design. Ah the brave new world of NoSQL eh? :-)"},{"Id":"2307382","PostId":"2334718","CreationDate":"2010-02-25T18:24:13.567","UserId":"98975","Body":"Thx for the answer! Couple of points - when you say the emphasis is on denormalization, that would basically imply that any &quot;joins&quot; that need to be done happen at the app level, but cassandra in effect distributes the query (assuming you use Random Partitioning)? Secondly - I guess I'm at a few hundred writes right now, but would much rather switch to a K-V store at this point than have to do it with a few 100k writes :) And lastly - even assuming that Django-NOSQL support still doesn't exist, is there anything that prevents real time querying of the Cassandra db through a REST API?"},{"Id":"2319839","PostId":"1248165","CreationDate":"2010-02-27T12:19:38.770","UserId":"217862","Body":"+1 for CAP theorem"},{"Id":"2319906","PostId":"1245379","CreationDate":"2010-02-27T12:36:35.777","UserId":"184730","Body":"Good explanation with columns."},{"Id":"2323966","PostId":"2287361","CreationDate":"2010-02-28T10:33:05.920","UserId":"85785","Body":"I have an open source c# client for redis @ http:\/\/code.google.com\/p\/servicestack\/wiki\/ServiceStackRedis it allows you to store 'typed POCOs' as text blobs and provides IList&lt;T&gt; and ICollection&lt;T&gt; interfaces for redis server-side lists and sets, etc."},{"Id":"2328444","PostId":"2354254","CreationDate":"2010-03-01T06:42:06.127","UserId":"16076","Body":"why do you want to &quot;... replace a relational database I have been using.&quot;??  "},{"Id":"2328448","PostId":"2354254","CreationDate":"2010-03-01T06:43:35.480","UserId":"69803","Body":"because the amount of data that will soon be stored (when a a new group that is coming on board starts automatically submitting data from their instruments) will apparently make the system very slow."},{"Id":"2328482","PostId":"2354254","CreationDate":"2010-03-01T06:56:28.813","UserId":"16076","Body":"A properly configured relational database, on good hardware will be able to cope with most loads."},{"Id":"2331556","PostId":"2357239","CreationDate":"2010-03-01T16:22:28.433","UserId":"171461","Body":"community wiki...."},{"Id":"2331646","PostId":"2357239","CreationDate":"2010-03-01T16:32:06.070","UserId":"129655","Body":"I admit to having no real experience with this, but I'd like to see some links backing up that claim or at least explaining what the alternatives are. I also agree that it should probably be community wiki."},{"Id":"2331675","PostId":"2357239","CreationDate":"2010-03-01T16:35:25.083","UserId":"120163","Body":"Would you please define &quot;non-relational&quot; as something other than &quot;isn't relational&quot;?   Otherwise any ad hoc scheme for storing data qualifies."},{"Id":"2331739","PostId":"2357239","CreationDate":"2010-03-01T16:43:14.037","UserId":"182172","Body":"you are right, Ira. I will change the question\n"},{"Id":"2331768","PostId":"2357239","CreationDate":"2010-03-01T16:46:01.457","UserId":"182172","Body":"...and converted into a community wiki, thanks jldupont and Platinum Azure"},{"Id":"2331792","PostId":"2357239","CreationDate":"2010-03-01T16:48:30.093","UserId":"92448","Body":"Keep in mind that 'non-relation' doesn't just mean the new NoSQL style data stores. There are other styles that have been around a long time, like Network, Hierarchical, and Object DBs."},{"Id":"2332000","PostId":"2357402","CreationDate":"2010-03-01T17:12:42.973","UserId":"146325","Body":"+1 - a thoughtful contribution"},{"Id":"2333767","PostId":"2359159","CreationDate":"2010-03-01T21:26:33.910","UserId":"204218","Body":"(I think that you'd get better answer on the Cassandra-users maillist.)"},{"Id":"2333827","PostId":"2359159","CreationDate":"2010-03-01T21:33:34.147","UserId":"58394","Body":"adamse: Thanks for the tip! That's probably so, but for the sake of future Cassandra users on Stackoverflow (a growing population!) I thinks it good to have the answer stored here too :-)"},{"Id":"2334443","PostId":"2334718","CreationDate":"2010-03-01T23:02:39.890","UserId":"130168","Body":"Cassandra routing is based on row key, so any query against a single row only has to hit one machine and is quite performant.\n\nA REST client api is a poor fit for Cassandra since it allows binary data, but more broadly, there's nothing stopping you from using the normal Python driver from django manually."},{"Id":"2342627","PostId":"2359282","CreationDate":"2010-03-02T21:42:55.363","UserId":"58394","Body":"+1: Great answer! Thanks!"},{"Id":"2342749","PostId":"2359282","CreationDate":"2010-03-02T22:03:13.347","UserId":"28589","Body":"Thanks. The Cassandra wiki is a good place to start if you want to have a more in-depth understanding\/description about terminology and nomenclature used in Cassandra"},{"Id":"2347405","PostId":"2358230","CreationDate":"2010-03-03T13:33:34.543","UserId":"69059","Body":"Thanks for mentioning MyNoSQL. Ben you can probably use the Rails tag to find all posts related to NoSQL and Rails: http:\/\/nosql.mypopescu.com\/tagged\/rails"},{"Id":"2349073","PostId":"2268101","CreationDate":"2010-03-03T16:39:33.280","UserId":"135881","Body":"This is great stuff are there any plans to release more documentation or to expand on how to search and retrieve documents?"},{"Id":"2349895","PostId":"2373364","CreationDate":"2010-03-03T18:17:10.580","UserId":"55408","Body":"Yes, I really like y-serial's approach, especially since it uses sqlite. Keep up the good work! Maybe when I get some time from my other projects, I'll try to do something similar in C# :)"},{"Id":"2350168","PostId":"2268101","CreationDate":"2010-03-03T18:52:03.047","UserId":"155862","Body":"Its the Mongo DB PHP driver. So you'd use the library as you would normally outside of CodeIgniter. Have you seen the Mongo DB PHP driver doc? http:\/\/www.php.net\/manual\/en\/book.mongo.php"},{"Id":"2350956","PostId":"2374517","CreationDate":"2010-03-03T20:36:15.437","UserId":"32577","Body":"Well don't i feel like an idiot. How did i not find that before."},{"Id":"2350961","PostId":"2374517","CreationDate":"2010-03-03T20:36:56.730","UserId":"84651","Body":"It happens to the best of us from time to time."},{"Id":"2364366","PostId":"2357107","CreationDate":"2010-03-05T12:12:55.537","UserId":"182172","Body":"they only show the bright side of the story... but good start point anyway. thanks Matthew"},{"Id":"2364383","PostId":"2357402","CreationDate":"2010-03-05T12:15:22.613","UserId":"182172","Body":"thank you all, very useful"},{"Id":"2366470","PostId":"2359175","CreationDate":"2010-03-05T16:41:08.803","UserId":"154146","Body":"Way to dive in and understand what's going on under the hood in Cassandra!"},{"Id":"2372116","PostId":"2358230","CreationDate":"2010-03-06T17:14:07.077","UserId":"6705","Body":"Thanks for pointing out the Rails tag!"},{"Id":"2373348","PostId":"2374517","CreationDate":"2010-03-06T22:40:16.727","UserId":"260555","Body":"The 4.8 release BerkeleyDb from Oracle actually comes with an official C# API.\n"},{"Id":"2381876","PostId":"1960576","CreationDate":"2010-03-08T14:53:51.897","UserId":"21668","Body":"He's talking about mongoid x mongo_mapper, what is the faster ruby gem to access mongo, not mongodb x couchdb."},{"Id":"2383122","PostId":"2403246","CreationDate":"2010-03-08T17:29:49.400","UserId":"91","Body":"Have they changed Firebird to support NoSQL approaches? (That is, storing objects rather than rows\/columns)"},{"Id":"2383148","PostId":"2403246","CreationDate":"2010-03-08T17:32:07.853","UserId":"184977","Body":"no they didnt. in fact fb sql is not nosql. but is usable for small applications as embedded."},{"Id":"2383160","PostId":"2403278","CreationDate":"2010-03-08T17:33:57.290","UserId":"184977","Body":"MongoDb is interesting. i want it try with asp.net"},{"Id":"2383262","PostId":"2403278","CreationDate":"2010-03-08T17:45:29.597","UserId":"75840","Body":"Yes, embedded in the application. I'm using WCF with C#. MonogoDB seems what I need. Thanks!"},{"Id":"2384811","PostId":"2404713","CreationDate":"2010-03-08T21:11:48.273","UserId":"153943","Body":"As I mentioned in my question, I'm not looking to add a read-only user; rather, I want to add a user who can only *write* records, without being able to modify or delete them after the fact."},{"Id":"2388068","PostId":"2403271","CreationDate":"2010-03-09T09:08:33.103","UserId":"260555","Body":"If you are considering BDB on Windows (poster says WCF and C#) then take a look at the built-in ESENT database engine as well. It is in the same class of functionality."},{"Id":"2389387","PostId":"2408877","CreationDate":"2010-03-09T12:24:58.697","UserId":"277683","Body":"How about an ORM?"},{"Id":"2389522","PostId":"1909257","CreationDate":"2010-03-09T12:45:27.127","UserId":"60956","Body":"Wise words.....\n"},{"Id":"2390413","PostId":"2408877","CreationDate":"2010-03-09T14:40:02.703","UserId":"238134","Body":"An ORM would make the handling more convenient, but the underlying data structure would still remain relational and probably the performance wouldn't be so good. "},{"Id":"2392015","PostId":"2405068","CreationDate":"2010-03-09T17:39:19.170","UserId":"153943","Body":"That's kind of what I suspected. I'm effectively enforcing read-only access right now by not exposing a raw connection to the database anywhere in the application code. That doesn't perfectly protect us from user error or malicious updates, but I'm we'll work out another durable audit log solution."},{"Id":"2392446","PostId":"2411472","CreationDate":"2010-03-09T18:31:02.030","UserId":"40015","Body":"Maybe we should write one then, if there really aren't any good alternatives?"},{"Id":"2392543","PostId":"2411472","CreationDate":"2010-03-09T18:42:10.093","UserId":"536","Body":"Sounds good to me. Send me a patch for that. :-)"},{"Id":"2392561","PostId":"2411472","CreationDate":"2010-03-09T18:44:58.133","UserId":"40015","Body":"Sorry, when I said &quot;we&quot;, I really meant &quot;you&quot; :-P"},{"Id":"2392694","PostId":"2411472","CreationDate":"2010-03-09T19:01:00.647","UserId":"536","Body":"Yep, so when I read &quot;we&quot;, I figured it meant &quot;you&quot;, Mr. Groves. ;-)\nAs for me, I've got my hands full at the moment."},{"Id":"2392883","PostId":"2411472","CreationDate":"2010-03-09T19:23:14.577","UserId":"40015","Body":"Well, if I still don't hear of any alternatives, I'll eventually start a project, which you will be welcome to participate in should your hands get freed up :)"},{"Id":"2393937","PostId":"2411472","CreationDate":"2010-03-09T21:39:48.070","UserId":"536","Body":"Fair enough. Email me if you start: judahgabriel at gmail"},{"Id":"2399318","PostId":"2417204","CreationDate":"2010-03-10T14:29:25.087","UserId":"40015","Body":"I didn't even think about LINQPad in that context: good call."},{"Id":"2401759","PostId":"2417204","CreationDate":"2010-03-10T19:03:23.000","UserId":"209899","Body":"Yes, LINQPad isn't a bad choice. But without the domain-classes (or in the Java world) it's useless. So the search for a excellent ad hoc query\/diagnostic tool for db4o goes on."},{"Id":"2402578","PostId":"2417204","CreationDate":"2010-03-10T20:31:28.137","UserId":"257786","Body":"But is that really a common scenario? I mean, you typically will have the model binaries at hand, won't you?"},{"Id":"2402631","PostId":"2420161","CreationDate":"2010-03-10T20:36:28.407","UserId":"166836","Body":"you might be better off asking for help on their mailing list."},{"Id":"2404676","PostId":"2404155","CreationDate":"2010-03-11T01:23:38.333","UserId":"153943","Body":"Since there doesn't seem to be a baked-in way, I've actually implemented a simple TCP proxy that sits in front of MongoDB and filters messages sent to the server by inspecting the opcode:\n\nhttp:\/\/gist.github.com\/328486"},{"Id":"2407984","PostId":"2420161","CreationDate":"2010-03-11T12:50:18.117","UserId":"124894","Body":"Do you have win 32 or win 64? On win 32 the max db size limit is 2 gigabyte. Maybe you ran into this limit? "},{"Id":"2410133","PostId":"2417204","CreationDate":"2010-03-11T16:41:36.760","UserId":"209899","Body":"Yes, you normally have the model binaries around. But would it be easier if you don't have to setup LINQPad? "},{"Id":"2410974","PostId":"2417204","CreationDate":"2010-03-11T18:10:39.440","UserId":"40015","Body":"Yeah it would be.  Do you know of something that does that? :)"},{"Id":"2417579","PostId":"2224193","CreationDate":"2010-03-12T14:15:19.053","UserId":"4069","Body":"How large is very large? On slide 41 of the presentation at http:\/\/www.slideshare.net\/jbellis\/cassandra-open-source-bigtable-dynamo you say &quot;Millions of columns per row&quot; for 0.5. Is columns in a row still the way to go for really big time series?"},{"Id":"2421679","PostId":"2285045","CreationDate":"2010-03-13T00:08:25.827","UserId":"22483","Body":"Don't forget solutions like GemStone\/S - a Smalltalk object store."},{"Id":"2421861","PostId":"2328263","CreationDate":"2010-03-13T00:51:33.260","UserId":"260805","Body":"I think I read somewhere that you could make couchdb do the compression automatically when the uncompressed data reached a certain level..."},{"Id":"2425554","PostId":"2440079","CreationDate":"2010-03-13T21:26:46.800","UserId":"180239","Body":"Do you mean 100 to 1k or 100k users an hour?"},{"Id":"2425562","PostId":"2440079","CreationDate":"2010-03-13T21:29:36.020","UserId":"24545","Body":"Cleared up the ambiguity :)"},{"Id":"2428726","PostId":"2442735","CreationDate":"2010-03-14T16:14:19.063","UserId":"10661","Body":"&quot;Are they good?&quot;  Berkley DB has been around for decades.  What more do you need to know?  &quot;Are there other options&quot;?  Always.  But, since you don't provide much background or guidance, it's hard to make a concrete suggestion."},{"Id":"2428766","PostId":"2442735","CreationDate":"2010-03-14T16:24:12.020","UserId":"74195","Body":"When you refer to non-sql database.  Are you concerned about a &quot;service-based&quot; SQL engine? vs a drop-in DLL such as others mentioned about SQLite (and also Sybase Advantage LOCAL Server).\n\nFor requests against &quot;traffic&quot;, you describe &quot;BIG&quot; Data, and that's all relative based on data normalization too."},{"Id":"2428986","PostId":"2442778","CreationDate":"2010-03-14T17:12:29.463","UserId":"257090","Body":"You'd make datasets relate to one another by storing more than a simple scalar in the value field. Berkely doesn't care what you store, it treats it as a blob of bytes."},{"Id":"2429084","PostId":"2440079","CreationDate":"2010-03-14T17:34:05.580","UserId":"76337","Body":"Please do at least a _little_ research first (maybe two minutes worth). Just take a quick look through http:\/\/stackoverflow.com\/questions\/tagged\/nosql."},{"Id":"2429552","PostId":"2443381","CreationDate":"2010-03-14T19:22:34.960","UserId":"54504","Body":"A document management system is not an RDBMS (in fact, it usually uses one to store the documents). Depending on how many data you expect to manage, query frequency and how many these return on average you could find out that a document system is not efficient at all. Please elaborate on why you think that the &quot;timestamp&quot; is best modeled as a document."},{"Id":"2429922","PostId":"2443712","CreationDate":"2010-03-14T20:53:29.717","UserId":"110933","Body":"do you have to use CouchDB? If alternatives are possible, you could do worse than look at some of the fairly stable APIs that are available for MongoDB."},{"Id":"2435177","PostId":"2445878","CreationDate":"2010-03-15T15:19:39.007","UserId":"28589","Body":"addition to jbellis answer: the client Thrift API is well explained on the Cassandra wiki page under the API section: http:\/\/wiki.apache.org\/cassandra\/API"},{"Id":"2437292","PostId":"2443712","CreationDate":"2010-03-15T19:36:47.990","UserId":"187511","Body":"The major reason I am exploring Couch over Mongo is Couch's claim of built-in versioning.  All versions of the majority of my models need to be retained indefinitely.  Unless I missed something in the Mongo documentation I don't believe this was built-in.  Obviously immutable models is fairly trivial (create a new model every time, sort by created_at, etc) but if its one less thing I have to worry about in my code that's all the better."},{"Id":"2437324","PostId":"2438758","CreationDate":"2010-03-15T19:40:39.877","UserId":"262158","Body":"i finally managed to install by execute this:\nmongod.exe --service"},{"Id":"2439970","PostId":"2452169","CreationDate":"2010-03-16T04:56:16.263","UserId":"129195","Body":"This might be better as a question and not a wiki."},{"Id":"2439990","PostId":"2452169","CreationDate":"2010-03-16T05:01:21.353","UserId":"171985","Body":"I am sorry,now i will correct it"},{"Id":"2439993","PostId":"2452216","CreationDate":"2010-03-16T05:02:09.620","UserId":"129195","Body":"Linq To Sql comes to mind as it's really easy and requires no code at all.  then maybe implement a repository pattern.  I removed my answer saying as much but then thought @amexn was thinking more in terms of MongoDB."},{"Id":"2439997","PostId":"2452216","CreationDate":"2010-03-16T05:04:48.663","UserId":"171985","Body":"I need db4o\/MongoDb Object Database"},{"Id":"2440006","PostId":"2452169","CreationDate":"2010-03-16T05:06:30.187","UserId":"129195","Body":"@amexn, could you please explain why you (need) mongodb rather than something a little more widely used such as linq2sql?  if all you want is objects representing your model then..."},{"Id":"2440018","PostId":"2452169","CreationDate":"2010-03-16T05:09:27.840","UserId":"171985","Body":"I read an article regarding Object Databases.so i need to try in my project http:\/\/weblogs.asp.net\/andrewrea\/archive\/2010\/03\/15\/first-toe-in-the-water-with-object-databases-db4o.aspx"},{"Id":"2441549","PostId":"2453646","CreationDate":"2010-03-16T10:57:25.160","UserId":"262158","Body":"@Ant: can you please elaborate? \n\nDo you mean, something like this?\nvar spec = new Document { { &quot;Oid&quot;, id } };"},{"Id":"2441654","PostId":"2453646","CreationDate":"2010-03-16T11:16:39.513","UserId":"262158","Body":"you are champ.. it works :)\nthanks for your help.."},{"Id":"2448113","PostId":"2457373","CreationDate":"2010-03-17T01:19:14.810","UserId":"257942","Body":"Thanks! (15 char limit)"},{"Id":"2451440","PostId":"2461892","CreationDate":"2010-03-17T12:59:07.987","UserId":"40015","Body":"Sounds like a good idea.  Maybe a LINQPad plugin would be easier?  Also, what about locking the db4o file when using OM?  That can be very frustrating."},{"Id":"2452232","PostId":"2461892","CreationDate":"2010-03-17T14:21:40.517","UserId":"157321","Body":"Not locking the file can lead to database corruption. The solution (IMHO) is to use it in C\/S mode (but your app needs to use the same mode of course)\n\nRegarding a LINQPad plugin it may have some potential issues (for instance licensing). To be honest, I am not used to LINQPad."},{"Id":"2452583","PostId":"2452216","CreationDate":"2010-03-17T15:01:35.023","UserId":"35128","Body":"he refers to object database as a system that directly store\/retrieve application objects (usually through binary serialization) as opposed to relational ones that store tables, rows etc."},{"Id":"2455437","PostId":"2443392","CreationDate":"2010-03-17T20:33:06.377","UserId":"13483","Body":"My apologies - I should have been more clear, looking for an open source\/free solution.\n"},{"Id":"2455460","PostId":"2443445","CreationDate":"2010-03-17T20:36:06.450","UserId":"13483","Body":"My initial ideas (assuming an RDBMS) were queries along the lines of:\n\nSELECT cols FROM table WHERE (date_stamp BETWEEN start AND end) AND (location_stamp NEAR lat, long);\n\nSorry, can't look up the exact syntax for the spatial query params at the moment.\n"},{"Id":"2455556","PostId":"2443392","CreationDate":"2010-03-17T20:48:42.993","UserId":"76337","Body":"SQL Server Express 2008 is free."},{"Id":"2463439","PostId":"2463324","CreationDate":"2010-03-18T19:40:11.820","UserId":"295027","Body":"I agree that giving up high-availability is pointless, but I think the dual features of consistent reads and conditional updates together do allow multi-item\/multi-domain transactions to be implemented.  Consistent reads will be needed, but not in the usual path I don't think (and maybe not implementing read-only operations at all).\nI have no need for multi-valued attributes - but they can obviously be used to advantage for storing versions, timestamps, transaction IDs etc for items.\n\nSo, if your answer is no, then I guess you've answered my question (just not the answer I hoped for).  \n\n"},{"Id":"2472419","PostId":"2479790","CreationDate":"2010-03-19T21:07:41.387","UserId":"138041","Body":"What about listing product tags ordered by rating? Or listing products by a tag ordered by rating?\nSuch query would require use of 2 indexes at the same time to be effective"},{"Id":"2476345","PostId":"2483530","CreationDate":"2010-03-20T18:03:36.317","UserId":"279623","Body":"Could you provide 2-3 examples of &quot;document databases&quot;?"},{"Id":"2477026","PostId":"2483530","CreationDate":"2010-03-20T21:02:02.383","UserId":"134967","Body":"http:\/\/en.wikipedia.org\/wiki\/Document-oriented_database"},{"Id":"2479213","PostId":"2486346","CreationDate":"2010-03-21T09:32:54.080","UserId":"70157","Body":"Please edit the description to explain what the actual problem is with what you've described. Ideally, what the goal is; the criterion for choosing between different systems."},{"Id":"2479372","PostId":"2486364","CreationDate":"2010-03-21T10:31:05.963","UserId":"298340","Body":"Yes, 0.5s is a problem, because expected in the near future a significant increase in the size of the table, so time for query will grow to.\n\nSure, db and queries was optimized.\n\nThere is no other functionality on this table, except searching similar documents."},{"Id":"2479373","PostId":"2486346","CreationDate":"2010-03-21T10:31:33.890","UserId":"271959","Body":"And what has EXPLAIN to say about your queries? Without a queryplan, nobody knows if you could speed things up. And without the proper indexes and settings in postgresql.conf, the database has to be slow. As said below, 1.5GB is nothing to worry about, has to be very fast. Unless you do the wrong things."},{"Id":"2480050","PostId":"2479790","CreationDate":"2010-03-21T13:59:09.963","UserId":"138041","Body":"It makes sense. Thanks for the link! Another idea i'm considering is to use external tools like sphinx search or maybe lucandra to select objects ordered by rating. Sphinx full text search works good for such tasks, but it doesn't support &quot;real-time&quot; updates of index."},{"Id":"2481838","PostId":"2476507","CreationDate":"2010-03-21T21:03:22.023","UserId":"105363","Body":"Thanks. I haven't found an article that would show how a NoSQL architecture solves the issue of multiple DB write servers. I'll see if I can find something to figure it out."},{"Id":"2484512","PostId":"2483530","CreationDate":"2010-03-22T09:32:44.470","UserId":"190822","Body":"Riak or Cassandra"},{"Id":"2484969","PostId":"2486346","CreationDate":"2010-03-22T10:53:58.037","UserId":"46235","Body":"What is the function get_count_by_doc_id doing?"},{"Id":"2486088","PostId":"2443392","CreationDate":"2010-03-22T13:41:11.263","UserId":"13483","Body":"But I believe there are restrictions on running it in a production environment?  Last time I checked it did, I'll double check.  Thanks!"},{"Id":"2486399","PostId":"2443392","CreationDate":"2010-03-22T14:18:39.433","UserId":"76337","Body":"@sobedai: there are no restrictions about production. There are limitations on database size (4GB, I believe)."},{"Id":"2488170","PostId":"2489708","CreationDate":"2010-03-22T17:37:07.047","UserId":"58394","Body":"Hi! Thanks for your answer. The binary protocol appears to have changed between 0.5 and 0.6, where Net::Cassandra::Easy seems to be targeting 0.6 only."},{"Id":"2489115","PostId":"2495141","CreationDate":"2010-03-22T19:38:43.883","UserId":"4913","Body":"Not familiar with Cassandra, but couldn't you run a query earlier to get the table structure, so you'd know how many columns are available?"},{"Id":"2489124","PostId":"2495141","CreationDate":"2010-03-22T19:41:09.997","UserId":"155201","Body":"Wonder if the developer who made this had an ex named Cassandra that he didn't like too much..."},{"Id":"2489147","PostId":"2495141","CreationDate":"2010-03-22T19:44:41.960","UserId":"58394","Body":"zigdon: Nope :-)  The &quot;table structure&quot; in Cassandra is dynamic in the sense that one row can have say five columns whereas the next row has say forty columns."},{"Id":"2492970","PostId":"2486346","CreationDate":"2010-03-23T09:20:16.733","UserId":"298340","Body":"It culate rows count with current doc_id:\nCREATE OR REPLACE FUNCTION testing.get_count_by_doc_id(integer)\nRETURNS bigint AS\n'SELECT count(doc_id) FROM testing.text_attachment WHERE doc_id = $1'\nLANGUAGE 'sql' IMMUTABLE;\n"},{"Id":"2493024","PostId":"2486364","CreationDate":"2010-03-23T09:29:16.653","UserId":"298340","Body":"this query reduce\n     -&gt;  HashAggregate  (cost=0.27..0.28 rows=1 width=4) (actual time=7.926..11.324 rows=1863 loops=1)\n\nline, but save only few milliseconds.\n"},{"Id":"2493679","PostId":"2496466","CreationDate":"2010-03-23T11:30:34.327","UserId":"58394","Body":"Excellent! Exactly what I was looking for! Thanks!"},{"Id":"2495379","PostId":"2500874","CreationDate":"2010-03-23T14:57:20.243","UserId":"130168","Body":"This is allowed with any partitioner in 0.6, btw."},{"Id":"2497451","PostId":"2502742","CreationDate":"2010-03-23T18:56:08.317","UserId":"52551","Body":"tbh with ORMs like Hibernate doing such a fantastic job of abstracting this sort of thing away I really don't see the point."},{"Id":"2497500","PostId":"2502742","CreationDate":"2010-03-23T19:01:49.727","UserId":"636","Body":"MongoDB is not really competing with NHibernate and relational databases in most cases. Look at the use cases list I linked to. Relational databases are truly awful for some situations and these alternative databases are better solutions. The OP may be incorrect in his use of the term object databases here too."},{"Id":"2497599","PostId":"2502742","CreationDate":"2010-03-23T19:17:17.553","UserId":"40015","Body":"640K should be enough for anyone."},{"Id":"2498122","PostId":"2502988","CreationDate":"2010-03-23T20:28:20.157","UserId":"4243","Body":"Sorry you had such a miserable experience.  If you're still interested, you could post what you're doing on http:\/\/groups.google.com\/group\/mongodb-user\/ and maybe we can help?  Importing should be very fast and the queries sound like you may have just needed an index somewhere or something."},{"Id":"2499307","PostId":"2502988","CreationDate":"2010-03-23T23:29:04.983","UserId":"25343","Body":"Not miserable at all. I'll add that my intent was to make the resulting MongoDB database &quot;correct&quot;. I wasn't trying to just make the load match the mysql database I have but instead construct a full document that represented each question, answer, votes and comments. Those are all denormalized in the dump and I think part of the issue was pulling them together. Regardless, the 32 bit limitation was my only true problem. I'm sure I could have spent more time making it work well if I could justify using it."},{"Id":"2499735","PostId":"2504591","CreationDate":"2010-03-24T01:30:35.650","UserId":"21239","Body":"http:\/\/stackoverflow.com\/questions\/1777103\/what-nosql-solutions-are-out-there-for-net"},{"Id":"2499826","PostId":"2504846","CreationDate":"2010-03-24T01:57:55.073","UserId":"52751","Body":"Which NoSQL solutions handle 100GBs of data well?"},{"Id":"2499841","PostId":"2504846","CreationDate":"2010-03-24T02:02:06.613","UserId":"3055","Body":"Well, you can try Apache Cassandra... From Cassandra website: &quot;Cassandra is in use at Digg, Facebook, Twitter, Reddit, Rackspace, Cloudkick, Cisco, &quot; ..."},{"Id":"2499843","PostId":"2504851","CreationDate":"2010-03-24T02:02:29.213","UserId":"52751","Body":"While I'd love to do any kind of end-to-end profiling, simple ALTER TABLE ADD KEY on 100GB+ table takes literally days, so I'm extremely limited in what kind of testing I can do. I see no hope of it ever scaling to multi-TB sizes."},{"Id":"2499853","PostId":"2504846","CreationDate":"2010-03-24T02:06:08.637","UserId":"3055","Body":"@taw Regarding your comment on `ALTER TABLE`, I want to add that some of these solutions such as CouchDB are schema-less ... which means that one document can look different from another--there are no enforced schema--which may help in your case."},{"Id":"2501111","PostId":"2505900","CreationDate":"2010-03-24T07:52:29.893","UserId":"52598","Body":"Do you only store the information or the associated files also?"},{"Id":"2501235","PostId":"2505900","CreationDate":"2010-03-24T08:21:50.380","UserId":"133298","Body":"Only the metadata of music, not the music itself."},{"Id":"2502397","PostId":"667673","CreationDate":"2010-03-24T11:30:40.580","UserId":"36710","Body":"@J M - Regarding products\/categories I wrote a blog post on that yesterday: http:\/\/blog.neo4j.org\/2010\/03\/modeling-categories-in-graph-database.html"},{"Id":"2502414","PostId":"2504851","CreationDate":"2010-03-24T11:33:15.550","UserId":"636","Body":"You need to do some more reading. This will help you profile mysql http:\/\/serverfault.com\/questions\/3120\/how-do-i-profile-mysql"},{"Id":"2502440","PostId":"2504846","CreationDate":"2010-03-24T11:37:23.390","UserId":"636","Body":"NoSQL databases might be more suitable for you but you will still have issues if you do not make an effort to understand the performance profile of your overall application. These databases bring different sets of issues that you need to be aware of. They are far from a slot in solution and need just as much DBA support (if not more)."},{"Id":"2505069","PostId":"2507634","CreationDate":"2010-03-24T16:16:33.610","UserId":"234031","Body":"this is incredibly old and fairly inaccurate."},{"Id":"2505086","PostId":"2506556","CreationDate":"2010-03-24T16:18:34.777","UserId":"234031","Body":"The above data format is perfect, if you want a view of all artists or albums by genre it's a simple map\/reduce function you just emit() for each genre :)"},{"Id":"2505213","PostId":"2509482","CreationDate":"2010-03-24T16:33:03.160","UserId":"197229","Body":"Can you consider finding a MySQL expert you can pay to spend a couple of days reviewing your DB?"},{"Id":"2505651","PostId":"2504833","CreationDate":"2010-03-24T17:16:20.243","UserId":"271959","Body":"200GB is not that much. Could it be the way your code uses the database? Might be missing indexes or even Amazon rds that's giving problems. Did you EXPLAIN your queries to see what's wrong?"},{"Id":"2506562","PostId":"2508839","CreationDate":"2010-03-24T19:04:44.703","UserId":"58394","Body":"jbellis: The problem is that I'm not sure it is a bug - therefore my question. The more likely scenario is that it is me invoking sstable2json incorrectly :-) Please let me know if you believe this to be a bug - then I'll JIRA it"},{"Id":"2506626","PostId":"2510680","CreationDate":"2010-03-24T19:11:48.940","UserId":"158595","Body":"Certain NoSQL systems, but if you consider the cases of memcache\/memcachedb, many of the systems are optimized for the exact opposite situation as well..."},{"Id":"2506719","PostId":"2510680","CreationDate":"2010-03-24T19:24:58.193","UserId":"636","Body":"A lot of people use Hadoop to process the contents of NoSQL stores and do statistics."},{"Id":"2506735","PostId":"2510666","CreationDate":"2010-03-24T19:27:03.827","UserId":"16957","Body":"Do you think a table with ~300k rows (just two columns) that's accessed about 7 times per minute on a worst case would be worth it or not?"},{"Id":"2506745","PostId":"2510666","CreationDate":"2010-03-24T19:28:22.260","UserId":"158595","Body":"Absolutely not... 300k rows is more or less nothing for the average RDBMS... I'm assuming one row is a timestamp, which would probably be your clustered index, and any database engine will make childsplay of any queries you run."},{"Id":"2506833","PostId":"2510666","CreationDate":"2010-03-24T19:42:25.007","UserId":"16957","Body":"Thanks! I guess I'll have to find a better excuse to play with a NoSQL system."},{"Id":"2506927","PostId":"2510666","CreationDate":"2010-03-24T19:53:29.637","UserId":"158595","Body":"Most of the times I've been able to justify going away from SQL solutions was when my dataset was greater than a billion records... Anything less than that you manage fairly well with an RDBMS"},{"Id":"2509513","PostId":"2504846","CreationDate":"2010-03-25T05:00:31.263","UserId":"3055","Body":"The OP does care about his choice of database and is working with a very large datasets. That alone should hint you that the OP can and will try to understand the performance profile of the application before he puts it to use. **NOTHING** is a slot in there is no need to state such general assumptions."},{"Id":"2513480","PostId":"2516752","CreationDate":"2010-03-25T15:26:52.707","UserId":"39430","Body":"I am not clear on what the question is."},{"Id":"2513631","PostId":"2516752","CreationDate":"2010-03-25T15:43:36.633","UserId":"54200","Body":"not only not clear about the question, but wonder how this get's 4 upvotes...."},{"Id":"2515819","PostId":"2224193","CreationDate":"2010-03-25T19:55:24.913","UserId":"28287","Body":"Yes, columns are the way to go."},{"Id":"2518479","PostId":"2520965","CreationDate":"2010-03-26T04:31:18.527","UserId":"184057","Body":"Well, thank you, BUT (there is always &quot;but&quot;, isn't it?):\n\n1. I don't want to build like that. I am not worried to grow. This is my requirement. I know what to expect and have my reasons for that. So just I need to take this as given; not because I am sure I am among those &quot;special&quot; who get so popular overnight - but it's just the way it needs to be done, and there are objective requirements, discussing which really goes beyond my question. Sorry.\n\n2. There is no any kind of adjustment in your solution for: often and multiple writes; changing the position of every player.\n\nUnfortunately ;-("},{"Id":"2524297","PostId":"2526192","CreationDate":"2010-03-26T19:38:18.293","UserId":"105929","Body":"define 'best'. Ie, what are the criteria that matter most to *you*"},{"Id":"2524466","PostId":"2520965","CreationDate":"2010-03-26T19:59:55.057","UserId":"282612","Body":"@alexeypro - when someone writes you such a long answer, well detailed, interesting and CORRECT, please be kind to at least give it a thumb-up even if you don't want to use it! :-)"},{"Id":"2524714","PostId":"2526192","CreationDate":"2010-03-26T20:27:50.477","UserId":"300588","Body":"i did, open source."},{"Id":"2525020","PostId":"2526192","CreationDate":"2010-03-26T21:06:58.230","UserId":"166390","Body":"No, seriously, define &quot;best&quot;. NoSQL is such a huge category. It does not really say what you want to do. Do you want a flat\/document DB? An object DB? A directed graph DB? It depends on what you need to do. After that decision is made then you can choose &quot;good candidates&quot; based on your functional requirements."},{"Id":"2525464","PostId":"2526192","CreationDate":"2010-03-26T22:16:21.677","UserId":"300588","Body":"for serving a wiki like website"},{"Id":"2526220","PostId":"2527682","CreationDate":"2010-03-27T00:48:42.473","UserId":"8457","Body":"Probably needs an Encode::decode_utf8 after reading.  (And really, an Encode::encode_utf8 for writes.)"},{"Id":"2527541","PostId":"2528954","CreationDate":"2010-03-27T10:53:13.053","UserId":"58394","Body":"Thanks for your answer, but I'm afraid that does not solve the problem since \\u{2603} is &quot;\u2603&quot; and not &quot;\u00e2&quot;. The output I'm expecting is hence &quot;OK: \u2603 == \u2603&quot; and not &quot;OK: \u00e2 == \u00e2&quot;."},{"Id":"2527594","PostId":"2528954","CreationDate":"2010-03-27T11:10:26.427","UserId":"74496","Body":"Oops, using PuTTY and forgot to set UTF-8 character set. I'll get back to you."},{"Id":"2527598","PostId":"2528954","CreationDate":"2010-03-27T11:12:06.317","UserId":"74496","Body":"With UTF-8 the code above shows &quot;OK: \u2603 == \u2603&quot;. Answer updated."},{"Id":"2527622","PostId":"2528954","CreationDate":"2010-03-27T11:21:38.157","UserId":"58394","Body":"Ah, excellent! That did the trick! Thanks a lot for your answer!"},{"Id":"2528249","PostId":"2529426","CreationDate":"2010-03-27T14:16:54.997","UserId":"4249","Body":"Which database in particular? There is not going to be a one-size-fits-all answer such as JDBC for RDBMS"},{"Id":"2529304","PostId":"2530300","CreationDate":"2010-03-27T18:28:04.540","UserId":"211450","Body":"E.g I have set of objects and weights of connections btw these objects. I want to find all possible paths and their weights btw any 2 objects quickly."},{"Id":"2530523","PostId":"2443381","CreationDate":"2010-03-28T00:51:30.180","UserId":"13483","Body":"I don't necessarily think that the timestamp is best modeled as a document.  It's just something I was considering.  As I stated below, in SQL-type language, I anticipate sets of queries between specific times and with locations.  Those two pieces of data would be the most common fields keyed on."},{"Id":"2530532","PostId":"2452169","CreationDate":"2010-03-28T00:54:38.963","UserId":"131060","Body":"Both MongoDB and db4o are independent databases - they replace, not work with, SQL Server 2005."},{"Id":"2534018","PostId":"2534408","CreationDate":"2010-03-28T20:40:47.130","UserId":"283037","Body":"its not an answer to your question, but it maybe still interesting to read article and comments to it: http:\/\/developers.slashdot.org\/story\/10\/03\/28\/1432234\/Why-Some-Devs-Cant-Wait-For-NoSQL-To-Die"},{"Id":"2534617","PostId":"2523733","CreationDate":"2010-03-28T22:50:56.090","UserId":"105363","Body":"Thanks for the links."},{"Id":"2538662","PostId":"2529426","CreationDate":"2010-03-29T14:09:17.143","UserId":"12631","Body":"The question is database independent. If you know a tool that work only with one NoSQL database then post it."},{"Id":"2540439","PostId":"2531507","CreationDate":"2010-03-29T17:42:59.993","UserId":"184057","Body":"Right, but do I need to count all users every N minutes? Sounds expensive. My other idea is to have it done through cache, where everything will be in cache, and it'll do the updates every N minutes.. though, not sure if there is still a better way of doing that."},{"Id":"2540823","PostId":"2540290","CreationDate":"2010-03-29T18:31:34.163","UserId":"202431","Body":"Marc edited the question, he didn't ask it."},{"Id":"2541172","PostId":"2540458","CreationDate":"2010-03-29T19:25:55.240","UserId":"304435","Body":"Thank you Gareth! I have continued my search and am thinking about putting the riak datastore on an external EBS volume for better performace and so that if an instance is deleted, I don't lose the data on that ec2-instance.  I suppose that would mean I start with one instance attached to multiple EBS disks, and then add instances and spread out the disks among them as I need performance. Am I thinking about this the right way?"},{"Id":"2541180","PostId":"2540290","CreationDate":"2010-03-29T19:27:10.310","UserId":"304435","Body":"Thank you Sean! (This is Tyler from raleigh ruby). I am new to all of this and will mail the team with a similar question. "},{"Id":"2541256","PostId":"2540290","CreationDate":"2010-03-29T19:38:13.403","UserId":"304435","Body":"Actually, I have just gotten riak setup and am beginning to play with some of its features. I am going to have to get my rails app setup to connect with EC2 so that I can deploy another instance on the fly. Of course, I am still learning how all of that really &quot;works&quot;, so off I go to read more!"},{"Id":"2541314","PostId":"2443445","CreationDate":"2010-03-29T19:45:51.733","UserId":"80458","Body":"R-tree does not transform lat\/long to a hash code, can you elaborate?"},{"Id":"2541747","PostId":"2528683","CreationDate":"2010-03-29T20:40:34.807","UserId":"10680","Body":"sweeeeeet. Thanks!"},{"Id":"2542450","PostId":"2540458","CreationDate":"2010-03-29T22:40:53.373","UserId":"10715","Body":"@tesmar, your approach sounds good - note that you can make an EBS volume pretty much as big as you like (although you pay per GB), so you may not need multiple volumes - again - I don't konw enough about Riak to answer that properly."},{"Id":"2546834","PostId":"2502742","CreationDate":"2010-03-30T13:45:39.027","UserId":"25300","Body":"Mongo != Object Database"},{"Id":"2548358","PostId":"2546948","CreationDate":"2010-03-30T16:53:26.547","UserId":"182467","Body":"Hundreds of fields which are shared with other rows means you might benefit from some normalization."},{"Id":"2549673","PostId":"2499659","CreationDate":"2010-03-30T19:57:33.230","UserId":"28589","Body":"hm, I think most the them are pretty self explained, as long as you are somewhat familiar with the Cassandra nomenclature."},{"Id":"2550166","PostId":"2499659","CreationDate":"2010-03-30T20:52:14.713","UserId":"58394","Body":"Schildmeijer: Feel free to skip the obvious ones :-)"},{"Id":"2552824","PostId":"2547768","CreationDate":"2010-03-31T06:55:13.397","UserId":"283181","Body":"Thanks a lot, you saved my life. Almost =)"},{"Id":"2557101","PostId":"2554024","CreationDate":"2010-03-31T16:51:24.577","UserId":"58394","Body":"Hi! The query is being issued once every five minutes. I've now updated my question with that info."},{"Id":"2562375","PostId":"2559411","CreationDate":"2010-04-01T09:35:50.333","UserId":"207036","Body":"better add subjective tag :)"},{"Id":"2562378","PostId":"2559411","CreationDate":"2010-04-01T09:36:23.100","UserId":"157247","Body":"Better yet, edit your question and tick the &quot;community wiki&quot; box."},{"Id":"2562470","PostId":"2559411","CreationDate":"2010-04-01T09:57:21.053","UserId":"17028","Body":"Gah, CW. And I was hoping to get some real rep and some street cred here. :-)"},{"Id":"2563928","PostId":"2559473","CreationDate":"2010-04-01T13:54:13.330","UserId":"242298","Body":"Please explain your definition of &quot;real&quot;."},{"Id":"2565356","PostId":"2559472","CreationDate":"2010-04-01T16:42:00.027","UserId":"234031","Body":"The process of scaling SQL solutions is the process of removing features and relationships. So I don't think this is an entirely fair assessment. Also, I wouldn't group NoSQL databases together like this, Cassanda for instance focuses solely on scaling *up* while CouchDB is concerned with scaling the api *down* and making it easy to use and attempts to allow that api to scale as far up as possible."},{"Id":"2565369","PostId":"2559411","CreationDate":"2010-04-01T16:43:35.373","UserId":"234031","Body":"can you explain a little more about your data set?"},{"Id":"2566378","PostId":"2562712","CreationDate":"2010-04-01T18:49:08.490","UserId":"28589","Body":"take a look at http:\/\/stackoverflow.com\/questions\/2445878\/cassandra-api-equivalent-of-select-from-where-id-in\/2448225#2448225"},{"Id":"2568444","PostId":"2564372","CreationDate":"2010-04-02T00:01:32.083","UserId":"101909","Body":"Just a note: you would create a template sqlite db file, and copy that for any time you needed to create a new collection. \n\nIf anyone wants to create a php setup to handle this and open source it, let me know. I think it would be great, but never bothered to make it myself."},{"Id":"2569741","PostId":"2565451","CreationDate":"2010-04-02T07:06:13.440","UserId":"115781","Body":"what's its advantages over sphinx? I heard that sphinx had a good performance"},{"Id":"2570149","PostId":"2559472","CreationDate":"2010-04-02T09:18:38.030","UserId":"6399","Body":"Might this be the link to the quote? http:\/\/www.25hoursaday.com\/weblog\/2010\/03\/29\/TheNoSQLDebateAutomaticVsManualTransmission.aspx"},{"Id":"2572244","PostId":"2564372","CreationDate":"2010-04-02T15:57:56.610","UserId":"55408","Body":"@RobKohr, your suggestions are in the direction of how y-serial does things. Have you seen it? http:\/\/yserial.sourceforge.net\/"},{"Id":"2572332","PostId":"2559472","CreationDate":"2010-04-02T16:12:54.977","UserId":"17028","Body":"Ah, yes indeed. I missed that he made it a public blog post as well. I'll update the post."},{"Id":"2572670","PostId":"2567411","CreationDate":"2010-04-02T16:55:38.637","UserId":"39677","Body":"are java based clients available that support all operations?"},{"Id":"2574542","PostId":"2564372","CreationDate":"2010-04-02T22:11:23.037","UserId":"101909","Body":"Nope, but I am looking for a php solution myself."},{"Id":"2577042","PostId":"2571210","CreationDate":"2010-04-03T14:54:18.743","UserId":"282658","Body":"You know, that &quot;aggressively recruit prolific coders&quot; thing is frightening at some level."},{"Id":"2578280","PostId":"2572635","CreationDate":"2010-04-03T21:02:52.233","UserId":"224004","Body":"Then aren't they the exact same thing, with different names?"},{"Id":"2579177","PostId":"2572635","CreationDate":"2010-04-04T03:35:27.080","UserId":"4243","Body":"There is a speed\/complexity trade off... I tried to clarify above."},{"Id":"2580508","PostId":"2574690","CreationDate":"2010-04-04T14:28:03.020","UserId":"100516","Body":"in-memory key-value store"},{"Id":"2580654","PostId":"2574694","CreationDate":"2010-04-04T15:01:51.500","UserId":"100516","Body":"It lacks transactions management and possibility to keep some data in the disk and another part in-memory and so on.. \/\/sarcasm"},{"Id":"2580754","PostId":"2574689","CreationDate":"2010-04-04T15:19:54.367","UserId":"139985","Body":"-1 for being vague, and for responding sarcastically to answers."},{"Id":"2580786","PostId":"2574689","CreationDate":"2010-04-04T15:27:10.460","UserId":"100516","Body":"@Stephen C: you are welcome to edit and provide better explanation. About &quot;responding sarcastically&quot;: it sounds strange for me that alternative to Berkeley DB is HashMap."},{"Id":"2580854","PostId":"2574694","CreationDate":"2010-04-04T15:40:32.577","UserId":"87197","Body":"Ah, I see :) There was a problem a while back with someone wanting to develop stuff for Android but needed to use a storage-backed hashmap because the size of his data was too large. Something similar, I guess."},{"Id":"2582161","PostId":"2574689","CreationDate":"2010-04-04T21:45:20.570","UserId":"15472","Body":"upvoting - question seems legit, and not that much sarcasm going around. Given, question could have stated from the start that hashmaps would not cut it."},{"Id":"2582671","PostId":"2574689","CreationDate":"2010-04-05T00:30:56.903","UserId":"139985","Body":"OK @Roman ... what **DO** you mean by &quot;\/\/sarcasam&quot; in your comment below??"},{"Id":"2583203","PostId":"2576838","CreationDate":"2010-04-05T03:53:28.980","UserId":"82344","Body":"Bullet point 1 seems impossible to fulfill if you aren't using a centralized database. Where do you think a local database is going to keep data? It has to go in files somewhere."},{"Id":"2583224","PostId":"2576838","CreationDate":"2010-04-05T03:59:48.377","UserId":"14955","Body":"@Mike Daniels: Could be encrypted files. "},{"Id":"2583239","PostId":"2576857","CreationDate":"2010-04-05T04:03:50.347","UserId":"166390","Body":"+1 ... for finding a sentence with more buzzwords than all of Microsoft the SharePoint documentation combined."},{"Id":"2583246","PostId":"2576838","CreationDate":"2010-04-05T04:05:45.683","UserId":"82344","Body":"@Thilo: OK, makes sense. I guess I was treating the two parts of bullet 1 as two separate requirements."},{"Id":"2583248","PostId":"2576857","CreationDate":"2010-04-05T04:06:52.343","UserId":"14955","Body":"@pst: Re: buzzwords: To be clear, the Prophet people are tongue-in-cheek about this themselves. &quot;Prophet's buzzword-laden pitch&quot; is a verbatim quote from the site."},{"Id":"2583257","PostId":"2576875","CreationDate":"2010-04-05T04:12:34.067","UserId":"82294","Body":"What's stopping a user from taking the encryption key from one machine to another?"},{"Id":"2583266","PostId":"2576875","CreationDate":"2010-04-05T04:16:08.840","UserId":"3043","Body":"@Dietrich - he said the key is matched to the hardware fingerprint"},{"Id":"2583307","PostId":"2576875","CreationDate":"2010-04-05T04:38:39.390","UserId":"14955","Body":"Also, the point may be to prevent other people from getting to the data, not necessarily the legitimate user (who knows the key)."},{"Id":"2583331","PostId":"2576857","CreationDate":"2010-04-05T04:50:11.607","UserId":"152253","Body":"@Thilo Thank you for pointinh Prophet. Did you check CouchDB or MongoDB? Did you find any of them suitable. Last release of Prophet was in Aug-2009 which makes me think it might not be actively developed in future, so reluctant to choose the same. Any how I will give a try."},{"Id":"2583342","PostId":"2576857","CreationDate":"2010-04-05T04:55:00.967","UserId":"14955","Body":"@Sundar: I looked at CouchDB when it was pretty new. At that time, it was unclear (at least to me) how to operate it in a peer-to-peer scenario. But yes, CouchDB is definitely something to check out. "},{"Id":"2583408","PostId":"2576857","CreationDate":"2010-04-05T05:18:05.247","UserId":"152253","Body":"@Thilo CouchDB seems to be promising. http:\/\/stackoverflow.com\/questions\/2576838\/which-database-to-choose\/2577012#2577012"},{"Id":"2583499","PostId":"2577012","CreationDate":"2010-04-05T05:59:09.343","UserId":"14955","Body":"Also, are there any tutorials about how to set up the bi-directional replication, and how conflicts are resolved there?"},{"Id":"2583831","PostId":"2577012","CreationDate":"2010-04-05T07:55:31.063","UserId":"152253","Body":"I was reading about replication. If we need bidirectional replication, it looks like we have to initiate replication on both sides. Following links might help:\n\nhttp:\/\/books.couchdb.org\/relax\/reference\/replication\nhttp:\/\/books.couchdb.org\/relax\/reference\/conflict-management"},{"Id":"2583872","PostId":"2577012","CreationDate":"2010-04-05T08:10:07.643","UserId":"152253","Body":"Additional links:\n* http:\/\/japhr.blogspot.com\/2010\/03\/extreme-couchdb-replication.html\n\n* http:\/\/blog.couch.io\/post\/468392274\/whats-new-in-apache-couchdb-0-11-part-three-new "},{"Id":"2583960","PostId":"2577012","CreationDate":"2010-04-05T08:46:11.973","UserId":"152253","Body":"One more: http:\/\/wiki.apache.org\/couchdb\/Replication_and_conflicts"},{"Id":"2584561","PostId":"2578080","CreationDate":"2010-04-05T11:41:42.840","UserId":"309151","Body":"Fair question. In some moment, I need to read a 900Megas csv file that I need in a Python dictionary, it takes ages a lot of time (~hours) and hangs up the whole system.\n\nThanks for your answer!"},{"Id":"2584566","PostId":"2577979","CreationDate":"2010-04-05T11:42:46.440","UserId":"309151","Body":"Sadly, the server installation option is not available, the network via wifi is quite flaky here. \nThanks for your reply!"},{"Id":"2584588","PostId":"2577983","CreationDate":"2010-04-05T11:46:32.313","UserId":"309151","Body":"No I have not done any profiling, I am an occasional programmer, will look at it and at the database speed comparison. \nThanks for your answer!\n"},{"Id":"2585157","PostId":"2578659","CreationDate":"2010-04-05T13:45:51.453","UserId":"309151","Body":"Hi Chris,\n\n&quot;It sounds like each department has their own feudal database, and this implies a lot of unnecessary redundancy and inefficiency.&quot;\n\nYou exactly got it here, sadly I can not change this without upper management support. So I still have this problem to solve :)"},{"Id":"2585164","PostId":"2578310","CreationDate":"2010-04-05T13:46:47.333","UserId":"309151","Body":"thanks!\nIt can be an interesting workaroud easy to do while I get a better solution!"},{"Id":"2585363","PostId":"2577967","CreationDate":"2010-04-05T14:26:11.683","UserId":"10661","Body":"&quot;I am using just plain text files for all this and unsurprisingly it is very slow.&quot;  That's shocking.  Flat files are the fastest possible way to process data.  What causes you to think your files are the culprit?  What measurements have you made?  Have you profiled?"},{"Id":"2585369","PostId":"2578080","CreationDate":"2010-04-05T14:27:29.043","UserId":"10661","Body":"@Eric: That's not sensible.  It should read in minutes.  Can you please provide profiling data?"},{"Id":"2585389","PostId":"2578659","CreationDate":"2010-04-05T14:31:16.617","UserId":"44309","Body":"@Eric -- your comment on @Chris's answer makes it clear that you are looking for a technical solution to what is fundamentally an organisational or management problem.  Only broken dreams and bitter tears lie ahead."},{"Id":"2585810","PostId":"2578659","CreationDate":"2010-04-05T15:36:23.333","UserId":"309151","Body":"Dear @High Performance Mark: I am aware of the organisational problems, sadly I still need to get the best approach to this with the tools I have."},{"Id":"2585818","PostId":"2578080","CreationDate":"2010-04-05T15:37:32.587","UserId":"309151","Body":"@S.Lott: @jinka already told me in his|her answer to look at profiling. I have not idea about how to do it, but I am looking some documentation about it atm. Any tips welcome!\nThanks!"},{"Id":"2586878","PostId":"2578310","CreationDate":"2010-04-05T18:33:57.713","UserId":"247542","Body":"I'm not sure this is such a good idea. Correct me if I'm wrong, but Pickle isn't a streaming format, so in order to generate a Pickle file, you'd first have to load *all* 900 megs into Python's memory before saving the Pickle file. Instead, I'd recommend making a CSV dump, which is natively supported by the mysqldump tool and the &quot;SELECT * INTO OUTFILE&quot; query syntax, and then running this output through gzip to compress it."},{"Id":"2586951","PostId":"2580277","CreationDate":"2010-04-05T18:44:31.483","UserId":"137149","Body":"thanks! good, but the answer is pretty generic. If you hear the talk will see the reagarding RDBMS the presenter was a lot specific and with real scenarios. I would like to see more explanations of this kind regarding NOSQL databases."},{"Id":"2587081","PostId":"2578659","CreationDate":"2010-04-05T19:02:40.167","UserId":"247542","Body":"@Eric, I feel your pain. A bad solution now is often better then the perfect solution never."},{"Id":"2587197","PostId":"2576088","CreationDate":"2010-04-05T19:15:15.023","UserId":"58394","Body":"Thanks for yet another excellent SO Cassandra answer! BTW, have you seen this question: http:\/\/stackoverflow.com\/questions\/2573106\/what-are-the-alternative-ways-to-model-mm-relations-in-cassandra"},{"Id":"2587493","PostId":"2576875","CreationDate":"2010-04-05T19:54:00.273","UserId":"82294","Body":"@Joel - Yes, but you can get the key from one computer, and copy it to another.  The key is just another piece of data."},{"Id":"2587571","PostId":"2576875","CreationDate":"2010-04-05T20:02:04.650","UserId":"289135","Body":"@Dietrich, you can copy it over, but if the key is tied to the HW fingerprint, it isn't going to validate, and thus won't decrypt the database."},{"Id":"2587809","PostId":"2452169","CreationDate":"2010-04-05T20:32:14.877","UserId":"174390","Body":"Why dont you revise your question to make it more clear? As other responded, MongoDB and DB40 are independent, they have nothing to do with SQL Server. Either you are going to use those two for your datastore or your question is wrong and you are talking about ORM Mappers."},{"Id":"2588844","PostId":"2581801","CreationDate":"2010-04-05T23:44:36.370","UserId":"41665","Body":"I'm not sure how non-e-commerce sites using NoSQL is relevant to this question."},{"Id":"2588893","PostId":"2577983","CreationDate":"2010-04-05T23:58:17.680","UserId":"32880","Body":"That comparison page is useless. They even start off with the disclaimer &quot;The numbers here are old enough to be nearly meaningless&quot;"},{"Id":"2588940","PostId":"2581460","CreationDate":"2010-04-06T00:14:57.057","UserId":"309151","Body":"Thanks was the kind of answer I was waiting for, however it would be nice if could you elaborate why mongodb is a good idea?"},{"Id":"2588950","PostId":"2578310","CreationDate":"2010-04-06T00:17:36.070","UserId":"309151","Body":"I liked from this idea that none of my desktop users would dare trying to open the 900Megas CSV file with Excel anymore (They love trying this!)\nIt was easy and quick to test, but I did not get any improvement."},{"Id":"2589724","PostId":"2577983","CreationDate":"2010-04-06T04:21:58.643","UserId":"54808","Body":"@JimB, You're right, fixed now."},{"Id":"2590392","PostId":"2581768","CreationDate":"2010-04-06T07:42:35.987","UserId":"207633","Body":"+1 Thank you for the nice points made. MySQL and memcached have proven there performance and reliability for quite some time now. I think for websites this still is the best solution for now. One question tho, what do you mean by ad-hoc queries and why does nosql lack that."},{"Id":"2590398","PostId":"2581859","CreationDate":"2010-04-06T07:45:42.017","UserId":"207633","Body":"+1 Indeed in the end I was questioning the solution to have a mix as you stated. But share your opinion on the unnecessary level of complexity. I will keep your points in mind."},{"Id":"2590407","PostId":"2581768","CreationDate":"2010-04-06T07:48:24.697","UserId":"124894","Body":"MongoDB offers good support for adhoc queries and adhoc creation of indexes. However I think that you should use an ACID database for anything that is related to money. "},{"Id":"2590414","PostId":"2581801","CreationDate":"2010-04-06T07:50:36.863","UserId":"124894","Body":"When you buy a book via Amazon, it is stored in Oracle. "},{"Id":"2590415","PostId":"2581792","CreationDate":"2010-04-06T07:50:45.490","UserId":"207633","Body":"+1 I think the technology is just too new to for an e-commerce website to rely on this system. The way it uses just JSON for is storage does trigger. I hope in the future this method can be used as a reliable method for money driven websites. Until then I will just stick with MySQL with memcached. "},{"Id":"2590426","PostId":"2581859","CreationDate":"2010-04-06T07:53:45.327","UserId":"207633","Body":"Do you have any ideas on the amount of extra memory it will cost to have both of them running. Maybe it will be a good idea to just have the catalogue loaded in mongodb. Let out the complexity, do you see any major benefits for this?"},{"Id":"2590461","PostId":"2581768","CreationDate":"2010-04-06T08:00:35.067","UserId":"241462","Body":"A number of NoSQL databases do provide &quot;views&quot; or &quot;indexes&quot; which allow for what I would call &quot;semi ad-hoc&quot; queries, but it's still no substitute for the ability to simply say `SELECT * FROM users INNER JOIN purchases on ... HAVING ...`"},{"Id":"2590497","PostId":"2581792","CreationDate":"2010-04-06T08:09:48.577","UserId":"101970","Body":"The newness of the technology isn't the issue - these tools are being used by some of the biggest sites on the net. However, the technology is designed to solve a completely different problem set and will likely never be the most appropriate choice for working with money."},{"Id":"2590733","PostId":"2581792","CreationDate":"2010-04-06T09:07:39.283","UserId":"207633","Body":"Ok I understand. Thank you for pointing that out"},{"Id":"2591439","PostId":"2581768","CreationDate":"2010-04-06T11:30:53.620","UserId":"124894","Body":"@codeka,\n\nThe indexes in MongoDB are real indexes, they are not &quot;indexes&quot;. MongoDB differs from CouchDB. It is of course true that you can't join in MongoDB. However you can index nested data. "},{"Id":"2593945","PostId":"2576875","CreationDate":"2010-04-06T16:52:28.270","UserId":"82294","Body":"How exactly do you tie a key to a HW fingerprint?  That doesn't make any sense to me."},{"Id":"2595046","PostId":"2582847","CreationDate":"2010-04-06T19:04:22.780","UserId":"309151","Body":"First of all, thanks a lot Arthur for this elaborated answer.\nYour pointers to Tokyo Tyrant, Redis and to the document-store link were exactly what I was hoping for when I launched my question. However, I was not expecting be told MySQL can also do the job.\n\nThe part of the virtual memory and thrashing was something I knew was happening but I did not understand exactly at tech level, thanks a lot for the explanation! \n\nMy application is *very simple* and it works exactly as my users want, the problem is sometimes they need to use it with a big files and that made my question here."},{"Id":"2595054","PostId":"2582847","CreationDate":"2010-04-06T19:05:31.173","UserId":"309151","Body":"Answering your questions:\n- Most of the desktop computers have 4 GB RAM.\n- Mixed environment GNU\/Linux and Windows.\n- very simple queries, it is mostly compare this and this column with this other and this other column of the second file. It would be pretty much:\n + &quot;GET row1 from DATABASE1&quot; (gives a csv line)\n + &quot;GET row2 from DATABASE2&quot; (gives a csv line)\n + compare 2nd element from row1.dabatase1 with 3rd element from row1.database1,\n + if the match, output the whole 2 rows to final report.\n- I do not need any full-text-search capability"},{"Id":"2596398","PostId":"2582847","CreationDate":"2010-04-06T22:29:45.377","UserId":"11926","Body":"MySQL also is a pretty fast KV-store, but not as fast as redis and I with the limited search you have to perform you can do it. A lot of heavy users of MySQL say &quot;\u201cNormalization is for sissies.\u201d Okay actually this is a quote from a blog post @http:\/\/code.flickr.com\/blog\/2010\/02\/08\/using-abusing-and-scaling-mysql-at-flickr\/. "},{"Id":"2597093","PostId":"2577012","CreationDate":"2010-04-07T01:26:34.010","UserId":"14955","Body":"If you are going with CouchDB, maybe take a look at Desktopcouch: http:\/\/www.freedesktop.org\/wiki\/Specifications\/desktopcouch"},{"Id":"2597224","PostId":"2576875","CreationDate":"2010-04-07T02:08:06.277","UserId":"289135","Body":"@Dietrich, suppose you buy some software and provide the following to the software vendor:\nName: Dietrich, HardwareFingerprint: 1234ABCD  \nThe vendor makes a string like this:\ns := 'DIETRICHDIETRICHDI' + '1234ABCD' + '20100407' + 'SECRETDATABASEKEY';\nKey := EncryptThis(S);  \nThen he sends you this:\nLicensed To: Dietrich\nKey:  D827292B5D696080A62FF9E7334BA64FE820303FE06B3789BB9054C23BA875AD47F43BADB21E85441E3660F801B78EE4B46DE4\n\nNow when the program runs, it uses an internal decryption key (in this case: 'SECRET') to extract those 4 pieces of info. (cont..)"},{"Id":"2597230","PostId":"2576875","CreationDate":"2010-04-07T02:10:29.237","UserId":"289135","Body":"(cont)\n  Now it knows your name: 'DIETRICH', and can validate that against the name that you enter.  Ok, so it knows it's you.  It knows the hardware figerprint that the software was licensed to. 1234ABCD, and compares that against the actual hardware key. Ok, good.  The date can be checked, whatever. If everything looks good up to this point, it can pull the database encryption code (in this case 'SECRETDATABASEKEY'), and use that to decrypt the data.  There you go."},{"Id":"2597241","PostId":"2576875","CreationDate":"2010-04-07T02:12:03.463","UserId":"289135","Body":"go to:  \nhttp:\/\/www.fyneworks.com\/encryption\/RC4-Encryption\/  \nKey: SECRET \nEncrypted Data: D8 27 29 2B 5D 69 60 80 A6 2F F9 E7 33 4B A6 4F E8 20 30 3F E0 6B 37 89 BB 90 54 C2 3B A8 75 AD 47 F4 3B AD B2 1E 85 44 1E 36 60 F8 01 B7 8E E4 B4 6D E4 Try it!"},{"Id":"2606263","PostId":"2577967","CreationDate":"2010-04-08T05:19:55.010","UserId":"11926","Body":"You had any luck with Redis?"},{"Id":"2614558","PostId":"2520965","CreationDate":"2010-04-09T02:10:25.080","UserId":"108056","Body":"@Etamar L, thank you."},{"Id":"2614571","PostId":"2520965","CreationDate":"2010-04-09T02:12:56.870","UserId":"108056","Body":"@alexeypro, can you explain to me what you asked in the original question that I didnt answer?\n\nAs I read your comment, you have new questions and expanded the question? or am I wrong?"},{"Id":"2615911","PostId":"2605862","CreationDate":"2010-04-09T08:15:08.070","UserId":"204218","Body":"What we really need to know if we should be able to answer your question is HOW you are using your data. What kind of queries you run over it."},{"Id":"2615933","PostId":"2605897","CreationDate":"2010-04-09T08:18:24.240","UserId":"204218","Body":"This is not entirely correct. NoSQL can fit very complex data as well, think graph databases for example. Then there is also the simpler key-value NoSQL datastores. There is a very wide variety of NoSQL solutions."},{"Id":"2615959","PostId":"2605897","CreationDate":"2010-04-09T08:23:08.127","UserId":"81179","Body":"@adamse: good point about the broadness of the NoSQL term, although I think a graph database would not be the best fit for meterological data ;-)"},{"Id":"2615969","PostId":"2605862","CreationDate":"2010-04-09T08:24:53.377","UserId":"6260","Body":"Ah, I forgot. Thanks, I've added two samples."},{"Id":"2615980","PostId":"2605897","CreationDate":"2010-04-09T08:26:06.437","UserId":"204218","Body":"No, obviously not :)"},{"Id":"2615988","PostId":"2605862","CreationDate":"2010-04-09T08:27:24.857","UserId":"54376","Body":"What exactly is giving you a headache? Management of the database? Performance? Aggregating the data? Something else? If its performance related, have you analysed the query plan for your queries - maybe you need better indexes, or to tune your database settings (PostgreSQL is great at this). How big is your dataset - disk wise. 1GB? More? Less?"},{"Id":"2616026","PostId":"2605862","CreationDate":"2010-04-09T08:35:15.790","UserId":"81179","Body":"Hard to tell without knowing all gory details about your table structure and specifics of your queries but you might gain a lot of (read) speed in a classic database by for example clustering your table on the date field (and providing appropriate indexes for your queries)..."},{"Id":"2617656","PostId":"2605285","CreationDate":"2010-04-09T13:00:45.073","UserId":"37055","Body":"I assumed as such but the blog post about it supporting Vmem soon was very useful, I will be waiting until 2.0 is released before considering any usage of Redis since currently my usage applications wouldn't need a 100% coverage in memory and only the hotspots would be important. This would also greatly offer the flexibility of running Redis in a low cost VPS and scale out if I ever need to instead of having to start from the higher scale since it would require enough memory for every object in it currently."},{"Id":"2617912","PostId":"2605912","CreationDate":"2010-04-09T13:28:53.573","UserId":"74305","Body":"care to explain the downvote?"},{"Id":"2618106","PostId":"2607947","CreationDate":"2010-04-09T13:49:50.150","UserId":"312262","Body":"That is incorrect. Oracle states that Materialized Views greatly increases performance.  http:\/\/www.oracle.com\/technology\/products\/oracle9i\/daily\/jul05.html"},{"Id":"2618126","PostId":"2607947","CreationDate":"2010-04-09T13:53:06.260","UserId":"39430","Body":"@JustinT: Of course their marketing will say that. The reality is that in some cases (read-heavy situations) they are great. In write-heavy situations, they are not great, which is the point I was making by specifying OLTP, above."},{"Id":"2618127","PostId":"2607947","CreationDate":"2010-04-09T13:53:17.790","UserId":"280526","Body":"Greatly Increases performance compared to what? &quot;Oracle9i significantly improves the functionality of materialized views&quot;..compared to how slow they were before. Not compared to NoSQL style architectures."},{"Id":"2618149","PostId":"2607947","CreationDate":"2010-04-09T13:54:29.717","UserId":"312262","Body":"@OrbMan, your original post simply said &quot;One reason is that materialized views will perform poorly in an OLTP-type situation.&quot; And nothing about write specific performance. If the application is read-heavy, your statement would be incorrect."},{"Id":"2618175","PostId":"2607947","CreationDate":"2010-04-09T13:57:13.210","UserId":"39430","Body":"@Justin - OLTP to me implies heavy writes. I will update the post to be explicit."},{"Id":"2618301","PostId":"2607923","CreationDate":"2010-04-09T14:10:37.373","UserId":"27491","Body":"I thought the real rationale behind NoSql was the fact that SQL does not scale to &gt; petabytes of data. The lack of normalization, and of advanced sql features in general (such as (coff) guaranteed consistency), is a result of, and more a side effect of, the distributed architecture, not an actual design goal."},{"Id":"2620028","PostId":"2549017","CreationDate":"2010-04-09T17:39:15.160","UserId":"59501","Body":"Ok, looks like it is still Cassandra; which is fine, it is a great project. I just want to ensure I am not missing an obvious contender here."},{"Id":"2621986","PostId":"2611362","CreationDate":"2010-04-09T22:32:38.407","UserId":"213269","Body":"What do you mean? Digg is not a database as what I know. NoSQL involves many different databases like graph-databases, document-oriented databases, there is also key-value databases."},{"Id":"2622071","PostId":"2611362","CreationDate":"2010-04-09T22:50:27.853","UserId":"292712","Body":"I added the precision that Digg said it is using cassandraDB as its backend. Can you elaborate on the &quot;graph database&quot; ? thx."},{"Id":"2622532","PostId":"2577967","CreationDate":"2010-04-10T00:58:07.267","UserId":"309151","Body":"I did not have time to make tests yet, I will report here to improve the question and its solution when i do."},{"Id":"2623573","PostId":"2584578","CreationDate":"2010-04-10T08:31:00.660","UserId":"15609","Body":"The file system isn't sufficient because I will want to synchronise the data with a web application at some point.  Therefore it needs to be in a &quot;web-ready&quot; format."},{"Id":"2623608","PostId":"2584578","CreationDate":"2010-04-10T08:47:43.920","UserId":"1583","Body":"What makes your files &quot;web-ready&quot;? As far as I know, most websites that serve files, store them on the filesystem."},{"Id":"2623742","PostId":"2611362","CreationDate":"2010-04-10T09:44:36.147","UserId":"36710","Body":"Regarding [graphdb](http:\/\/en.wikipedia.org\/wiki\/Graph_database): see my answers [here](http:\/\/stackoverflow.com\/questions\/1047595\/) and [here](http:\/\/stackoverflow.com\/questions\/1899843\/) and [here](http:\/\/stackoverflow.com\/questions\/1189911\/non-relational-database-design\/1192822#1192822). You should find some blog entries by me and others here as well: [planet.neo4j.org](http:\/\/planet.neo4j.org\/)."},{"Id":"2627628","PostId":"2528749","CreationDate":"2010-04-11T04:01:02.427","UserId":"10680","Body":"This is a perfectly valid answer, sorry I can't pick two, the other one was more specifically an answer to my issue with Cassandra."},{"Id":"2634171","PostId":"2621849","CreationDate":"2010-04-12T12:11:28.670","UserId":"89771","Body":"Thanks oedo, do you mind explaining in more detail how the indexing works?"},{"Id":"2634408","PostId":"2621849","CreationDate":"2010-04-12T12:43:36.993","UserId":"297484","Body":"conceptually speaking, an index is a quick lookup into some useful value, and so the implementation depends on the database, and sometimes the configuration of said database. couchdb's system is detailed http:\/\/couchdb.apache.org\/docs\/overview.html under 'view indexes'. if you're looking for the actual algorithms maybe a look at the actual db system code, couchdb is open source after all :)"},{"Id":"2635560","PostId":"2619851","CreationDate":"2010-04-12T15:16:07.747","UserId":"184057","Body":"Can you suggest best way of implementing the described functionality for Cassandra\/HBase? My &quot;own&quot; way is just my guess, what I would like to find out, what's the best practices here are."},{"Id":"2640598","PostId":"2619851","CreationDate":"2010-04-13T07:05:30.400","UserId":"101970","Body":"All this is a bit new for real best practices to exist, but the method you describe is fairly close to standard. The main improvement you need is to use whatever support your chosen platform has for lists, so that you can add items without loading the whole list. With Cassandra you would probably use a supercolumn. If you have a pure key-value store like memcached, you can implement lists as values, but you need to implement locks and possibly queues also. "},{"Id":"2652003","PostId":"2634955","CreationDate":"2010-04-14T13:43:52.810","UserId":"70847","Body":"Probably should be CW? This is pretty much just NoSQL vs Relational databases, which is pretty subjective IMO."},{"Id":"2652025","PostId":"2634955","CreationDate":"2010-04-14T13:45:19.627","UserId":"46304","Body":"I would like to know if is is suitable for messaging system.  I assume if Twitter use it then it would be okay, however they might not use it for all of Twitter?"},{"Id":"2652923","PostId":"2638093","CreationDate":"2010-04-14T15:19:19.273","UserId":"46304","Body":"Well Column Families can have multiple columns in Cassandra, correct?"},{"Id":"2653246","PostId":"2638093","CreationDate":"2010-04-14T15:57:43.257","UserId":"28589","Body":"Yes, and it also allows to have SuperColumns"},{"Id":"2658608","PostId":"2638093","CreationDate":"2010-04-15T08:10:57.440","UserId":"35500","Body":"Plus this is just cassandra. If you're talking about NoSQL, well hell, look at MongoDB's data model, arrays and hashes nested as far as you can fit in a 4MB row. Indexable as well."},{"Id":"2669028","PostId":"2605862","CreationDate":"2010-04-16T12:31:41.080","UserId":"6260","Body":"@Mike: The current database is around 30gb on disk, but future expansions will increase those to 100-300gb.\n\nQueries are analyzed and tables indexed accordingly.\n\nWhat gives us headaches is the general, well, size of things. Backups, replication restauration, bulk inserts with heavy indexing activities are all taking longer and longer.\n\n\n@ChristopheD: Clustering is definitly something we're looking into."},{"Id":"2669088","PostId":"2609462","CreationDate":"2010-04-16T12:40:21.493","UserId":"6260","Body":"I'll have a look at Cassandra. Thanks for the input."},{"Id":"2669091","PostId":"2605897","CreationDate":"2010-04-16T12:40:46.423","UserId":"6260","Body":"Thanks for your comments."},{"Id":"2670121","PostId":"2653705","CreationDate":"2010-04-16T14:47:42.377","UserId":"142017","Body":"Excellent, thanks man."},{"Id":"2673313","PostId":"2642911","CreationDate":"2010-04-16T23:10:23.123","UserId":"252373","Body":"I don't see reason for using 2 tables, can you explain please? Can't I select DISTINCT on rows from same table?"},{"Id":"2690084","PostId":"2671423","CreationDate":"2010-04-19T22:56:31.893","UserId":"69742","Body":"I've been told by almost everyone that once you start making dynamically generated fields in a database, you should move to a NoSQL database.. Also, note that you don't have to use NoSQL for everything, you could always do a hybrid solution. "},{"Id":"2690281","PostId":"2671423","CreationDate":"2010-04-19T23:55:22.517","UserId":"112311","Body":"They hybrid solution is my plan.\n\nI'm just interested on peoples thoughts on performance, maintenance, and how I could link a hybrid solution together (e.g. assign an arbitary document ID field when documents are loaded, then use this ID field in the SQL tables? Or if I should rely on a NOSQL generated key."},{"Id":"2693195","PostId":"2671423","CreationDate":"2010-04-20T11:01:49.503","UserId":"124894","Body":"I don't understand the requirements. What do you mean with &quot;The basic premise is that it stores documents, each with their own particular indexes&quot;? Are we talking about free text indexes or indexes on metadata? Or do you mean &quot;metadata&quot; when you say &quot;index&quot;? "},{"Id":"2694750","PostId":"2675904","CreationDate":"2010-04-20T14:28:57.400","UserId":"79078","Body":"Thanks for the answer :) The connector I'm using seems to have problem with views, but I'll try this thing with custom IDs."},{"Id":"2698999","PostId":"2671423","CreationDate":"2010-04-20T23:47:24.177","UserId":"112311","Body":"Apologies for not being as clear. It's metadata (e.g. an invoice document will have an invoice number piece of metadata). It's these pieces of metadata which the users search on, and they change from client to client. I.e. one client might have an invoice document type, whereas another will have an application form document type."},{"Id":"2699063","PostId":"2675904","CreationDate":"2010-04-21T00:02:42.707","UserId":"2938","Body":"Documents with the same `_id` **are** different versions of the same document."},{"Id":"2700799","PostId":"2671423","CreationDate":"2010-04-21T07:49:33.820","UserId":"124894","Body":"You can use MongoDB gridfs for storing files and you can add metadata too. It's up to you to define what kind of metadata. I'm not sure if you can create an index on that metadata. I think you can but I have never tried. See http:\/\/www.mongodb.org\/display\/DOCS\/GridFS+Specification I will try. "},{"Id":"2701159","PostId":"2675904","CreationDate":"2010-04-21T08:59:31.387","UserId":"79078","Body":"Worked like charm, thanks :)"},{"Id":"2701849","PostId":"2682205","CreationDate":"2010-04-21T11:01:36.873","UserId":"208809","Body":"So the question is, how to have relations when using a non-relational NoSQL database? Out of curiosity, what are you building that MySQL wouldn't scale for?"},{"Id":"2701897","PostId":"2682205","CreationDate":"2010-04-21T11:07:19.940","UserId":"315947","Body":"Yes, thats the question.  \nWe are thinking to develop an application (which will mainly be a Classified Gateway where website developer will set\/get data through API)."},{"Id":"2706620","PostId":"2685181","CreationDate":"2010-04-21T20:21:48.947","UserId":"315947","Body":"I am not talking on traffic volume.. I prefer cassandra for its performance... See the Architecture of cassandra http:\/\/wiki.apache.org\/cassandra\/ArchitectureOverview\n\nMySQL Require 300ms to write with 50GB data where cassandra require only 0.12ms .. it is fastest data engine\nMySQL require 350ms to read with 50GB data where cassandra require only 15ms read \n\nThe most popular websites are migrating to cassandra for scaling and improving performance including facebook, twitter, digg etc...."},{"Id":"2709366","PostId":"2688350","CreationDate":"2010-04-22T05:48:05.060","UserId":"184057","Body":"Well, MySQL might be soon exchanged to any key\/value storage, etc. And the schema is quite complex to do the searches, as I mentioned - it'll have at least 2-4 JOINs with every search query. I really would like to get some advice about Hadoop implementation (will it work for real time? not?), than suggestion to change it to SQL schema. Let's just assume it's not SQL. :-) Let's say it's any key value storage, storing Protobuf object. Sounds better? I still need to do the search."},{"Id":"2711650","PostId":"2685181","CreationDate":"2010-04-22T12:20:09.107","UserId":"223992","Body":"These headline figures look impressive - but there's no details on how they configured the tests. Also, even using the latest fibre channel switched fabric (i.e. the fastest disk technology available) you'd be lucky to get a sustained 20Gb\/s - and that assumes that the underlying disks can cope with this rate\/volume of data - or 20,000 times slower than the figures cited for Cassandra on this page. Indeed, 20Gb\/s is about the memory bandwidth of a mid\/high-range non-NUMA system. The only way these figures could possibly make any sense is if you are looking at a very large database cluster."},{"Id":"2714646","PostId":"2688305","CreationDate":"2010-04-22T17:37:47.513","UserId":"21339","Body":"How big are the blobs?  Is the data largely structured data or are there unstructured elements as well (like full text)?"},{"Id":"2715307","PostId":"2688305","CreationDate":"2010-04-22T19:03:53.707","UserId":"184057","Body":"Yes, structured and unstructured data + arbitrary attributes in some cases"},{"Id":"2715845","PostId":"2694073","CreationDate":"2010-04-22T20:11:56.420","UserId":"38360","Body":"Who calls NoRM an ORM?  I thought it was a recursive acronym for &quot; **Not** an Object Relational Mapper.&quot;  Or maybe it's just &quot;Not a Relational Mapper&quot;, since the &quot;o&quot; is lowercase.  Either way, it's definitely not an ORM!"},{"Id":"2716077","PostId":"2694044","CreationDate":"2010-04-22T20:47:10.023","UserId":"38360","Body":"By the way, I kind of glossed over the parenthetical remark in my answer, but you said &quot;other NoSQL database APIs worth their salt&quot; - MongoDB is *very* different from something like bigtable or cassandra, and queries\/mapping against those data stores actually tend to be much more *difficult* than SQL.  Imagine implementing an entire data-driven app with nothing but `Dictionary&lt;,&gt;` instances.  It's not that bad, but it's close."},{"Id":"2716667","PostId":"2694044","CreationDate":"2010-04-22T22:03:58.433","UserId":"69742","Body":"@Aaro well of course with a key-value database, the API is very simplistic. What I meant by worth-its-salt is that you don't have to generate your own JSON queries or similar low level things. "},{"Id":"2716820","PostId":"2694044","CreationDate":"2010-04-22T22:31:56.050","UserId":"38360","Body":"@Earlz: Isn't that precisely what a mapper does?  These features aren't built-in, not even in Mongo."},{"Id":"2722341","PostId":"2694044","CreationDate":"2010-04-23T15:25:59.573","UserId":"69742","Body":"@Aar.. hm... I suppose you may be correct"},{"Id":"2723060","PostId":"2700318","CreationDate":"2010-04-23T16:46:56.403","UserId":"210304","Body":"Thank yo very much =)"},{"Id":"2724725","PostId":"2694961","CreationDate":"2010-04-23T20:30:49.777","UserId":"184057","Body":"Yes, the only other candidate was Solr. Thanks."},{"Id":"2727292","PostId":"2703828","CreationDate":"2010-04-24T08:56:02.630","UserId":"9990","Body":"What sort of caching do you use, memcached or a reverse proxy?"},{"Id":"2727299","PostId":"2703828","CreationDate":"2010-04-24T09:00:48.077","UserId":"74089","Body":"I use memcached."},{"Id":"2727376","PostId":"2703828","CreationDate":"2010-04-24T09:33:06.010","UserId":"73226","Body":"High cardinality means that the data is very selective and an index will definitely help. It is low cardinality columns where it won't be used."},{"Id":"2727582","PostId":"2703959","CreationDate":"2010-04-24T10:35:23.010","UserId":"74089","Body":"Thanks G\u00f6ran for an interesting answer!"},{"Id":"2731481","PostId":"2707570","CreationDate":"2010-04-25T08:12:08.140","UserId":"89021","Body":"Thank you. I do not specify because I want to avoid my question being tagged with languages. Libraries, Objects, inheritance, everything possible here."},{"Id":"2737108","PostId":"2707570","CreationDate":"2010-04-26T09:09:20.367","UserId":"89021","Body":"It was not easy to accept an answer because they are both very good and helped me. Thank you very much."},{"Id":"2739191","PostId":"2641482","CreationDate":"2010-04-26T14:25:14.840","UserId":"13376","Body":"What is the advantage of sql when using fininacial data?"},{"Id":"2743659","PostId":"2641482","CreationDate":"2010-04-27T00:28:41.567","UserId":"101970","Body":"The schema is unlikely to change, it fits well in a table structure, and lost\/inconsistent data could cause real problems."},{"Id":"2749095","PostId":"2641482","CreationDate":"2010-04-27T16:00:50.473","UserId":"13376","Body":"I don't understand why inconsistent data can cause real problems with banks. Scenario:You have one bank account, with $100 on above the limit on it, and two bank cards. When you try to withdraw money with the two cards at the same time at 2 different ATMs, you will get 2 times $100, and a letter with an extra fee in your mail box. The bank earns money (the extra fee for being below the limit) by using inconsistent data. It's to hard to connect all ATMs in the world with each other through one large relational database. Can you give an example where inconsistent financial data can be a problem?"},{"Id":"2751722","PostId":"2721623","CreationDate":"2010-04-27T20:59:05.353","UserId":"302268","Body":"Why you think Neo4j is better? The clojure support seems not have been updated since last year."},{"Id":"2751727","PostId":"2721292","CreationDate":"2010-04-27T20:59:21.907","UserId":"302268","Body":"What is better or different about Redis?"},{"Id":"2753455","PostId":"2641482","CreationDate":"2010-04-28T02:26:20.533","UserId":"101970","Body":"That stuff is all COBOL and batch processing, and not nearly as well designed\/stable as you might think. ATMs do not connect to any sort of unified data store, so are hardly a suitable example. It's like saying SQL isn't suitable for web apps because you can't give everyone on the internet direct access to your database.\n\nBesides, I never said anything about banks - think things like orders on an ecommerce site where you don't have to deal with an organization so conservative that SQL is considered new and untrusted."},{"Id":"2755141","PostId":"2641482","CreationDate":"2010-04-28T08:50:47.293","UserId":"13376","Body":"So the only reason is conservatism, no technical reason?"},{"Id":"2755482","PostId":"2721292","CreationDate":"2010-04-28T09:41:46.580","UserId":"232760","Body":"sorry, i have no info about other DBs, you mentioned. \n\ni just added &quot;redis&quot; to your list the DB, which i tried to use with Clojure. \nit runs ok, but there were some problems with build on Windows. \n"},{"Id":"2756292","PostId":"2721623","CreationDate":"2010-04-28T11:48:13.783","UserId":"36710","Body":"I didn't claim it was better than something else :-) But from what I've seen graph data + Clojure makes a good fit. The last commit on the bindings was just a week ago here: http:\/\/github.com\/bobby\/clojure-neo4j"},{"Id":"2757329","PostId":"2729981","CreationDate":"2010-04-28T13:50:15.887","UserId":"39430","Body":"You have provided zero information about your requirements."},{"Id":"2757336","PostId":"2729981","CreationDate":"2010-04-28T13:50:41.633","UserId":"83982","Body":"It mostly depends on your needs."},{"Id":"2760416","PostId":"2729981","CreationDate":"2010-04-28T19:57:14.170","UserId":"327761","Body":"This is question about NoSQL at all, not related to someone needs."},{"Id":"2760473","PostId":"2729981","CreationDate":"2010-04-28T20:05:01.080","UserId":"156415","Body":"well, depending on your situation, the best choice will change because they don't have all the same features. Do you need a highly Scalable solution? or is it just a small store? do you need to perform searches? or just fetch by keys? Is it mostly Read? Write? Both? performance differ from one to another. Thus the question asking you to precise your requirements"},{"Id":"2761675","PostId":"2641482","CreationDate":"2010-04-28T23:34:54.323","UserId":"101970","Body":"You seem to be missing the point. Technically anything is possible, using any set of tools, but that doesn't make it a good idea. For tracking sales, the benefits of sql outweigh the disadvantages. If you think you can set up a banking system using new technology, good luck to you."},{"Id":"2772350","PostId":"2723620","CreationDate":"2010-04-30T08:35:02.607","UserId":"13995","Body":"from the mongo db site I see, just saying :-)"},{"Id":"2773987","PostId":"2723620","CreationDate":"2010-04-30T13:31:27.160","UserId":"295964","Body":"It is clearly indicated that it is the mongo site.  "},{"Id":"2777458","PostId":"2747701","CreationDate":"2010-04-30T21:24:27.423","UserId":"261385","Body":"I'm kind of surprised that you have such a huge problem and no existing database infrastructure.  How has your system worked up until now?"}]}
